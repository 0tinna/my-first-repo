# 自动化运维脚本指南：Bash 与 Python 从入门到实战

## 目录

1. [Bash 脚本基础](#bash-脚本基础)
2. [Bash 进阶与实战](#bash-进阶与实战)  
3. [Python 脚本基础](#python-脚本基础)
4. [Python 进阶与实战](#python-进阶与实战)
5. [综合实战案例](#综合实战案例)
6. [实用脚本小工具](#实用脚本小工具)

## Bash 脚本基础

### 初始 Bash 脚本

从一个简单的脚本开始，了解基本语法和脚本执行方式。

```bash
#!/bin/bash
# 这是我的第一个Bash脚本
echo "Hello, World!"
echo "当前时间是: $(date)"
echo "当前用户: $USER"
echo "当前目录: $PWD"
```

保存为 `hello.sh` 并执行：

```bash
chmod +x hello.sh  # 添加执行权限
./hello.sh         # 执行脚本
```

### 变量与数据类型

```bash
#!/bin/bash
# 变量示例

# 定义变量（注意=两边不能有空格）
name="小明"
age=25
is_student=true

# 使用变量
echo "姓名: $name"
echo "年龄: $age"
echo "是否是学生: $is_student"

# 命令输出赋值给变量
current_date=$(date +%Y-%m-%d)
echo "今天是: $current_date"

# 只读变量
readonly MAX_CONNECTIONS=100
echo "最大连接数: $MAX_CONNECTIONS"

# 变量作用域
local_var="我是局部变量"  # 在函数外定义local变量会报错

# 数组
fruits=("苹果" "香蕉" "橙子" "葡萄")
echo "第一个水果: ${fruits[0]}"
echo "所有水果: ${fruits[@]}"
echo "水果数量: ${#fruits[@]}"
```

### 条件判断

```bash
#!/bin/bash
# 条件语句示例

# 基本if语句
echo "请输入一个数字:"
read number

if [ $number -gt 10 ]; then
    echo "输入的数字大于10"
elif [ $number -eq 10 ]; then
    echo "输入的数字等于10"
else
    echo "输入的数字小于10"
fi

# 文件测试
file_path="/etc/passwd"
if [ -f "$file_path" ]; then
    echo "$file_path 是一个普通文件"
fi

if [ -d "/tmp" ]; then
    echo "/tmp 是一个目录"
fi

if [ -r "$file_path" ]; then
    echo "$file_path 可读"
fi

# 字符串比较
name="admin"
if [ "$name" = "admin" ]; then
    echo "欢迎管理员"
fi

# 逻辑运算
age=25
if [ $age -ge 18 ] && [ $age -le 60 ]; then
    echo "成年人"
fi

# 使用 case 语句
echo "请输入一个水果名称:"
read fruit

case $fruit in
    "苹果")
        echo "这是一个苹果"
        ;;
    "香蕉"|"橙子")
        echo "这是香蕉或橙子"
        ;;
    *)
        echo "未知水果"
        ;;
esac
```

### 循环结构

```bash
#!/bin/bash
# 循环示例

# for循环
echo "for循环示例 - 数字:"
for i in 1 2 3 4 5; do
    echo "数字: $i"
done

echo "for循环示例 - 范围:"
for i in {1..5}; do
    echo "数字: $i"
done

echo "for循环示例 - 带步长的范围:"
for i in {1..10..2}; do  # 从1到10，步长为2
    echo "数字: $i"
done

echo "for循环示例 - 类C语法:"
for ((i=0; i<5; i++)); do
    echo "数字: $i"
done

# while循环
echo "while循环示例:"
count=1
while [ $count -le 5 ]; do
    echo "计数: $count"
    count=$((count + 1))
done

# until循环 (直到条件为真才停止)
echo "until循环示例:"
count=1
until [ $count -gt 5 ]; do
    echo "计数: $count"
    count=$((count + 1))
done

# 循环控制 - break和continue
echo "break示例:"
for i in {1..10}; do
    if [ $i -eq 6 ]; then
        break
    fi
    echo "数字: $i"
done

echo "continue示例:"
for i in {1..10}; do
    if [ $i -eq 6 ]; then
        continue
    fi
    echo "数字: $i"
done
```

### 函数

```bash
#!/bin/bash
# 函数示例

# 基本函数定义
function hello() {
    echo "Hello, World!"
}

# 调用函数
hello

# 带参数的函数
function greet() {
    echo "Hello, $1!"
}

greet "小明"
greet "小红"

# 返回值
function add() {
    local result=$(($1 + $2))
    echo $result
}

sum=$(add 5 3)
echo "5 + 3 = $sum"

# 局部变量
function test_scope() {
    local local_var="局部变量"
    global_var="全局变量"
    echo "函数内: $local_var"
    echo "函数内: $global_var"
}

test_scope
echo "函数外: $global_var"
echo "函数外: $local_var"  # 这个会输出空，因为local_var是局部变量
```

### 输入与输出

```bash
#!/bin/bash
# 输入输出示例

# 基本输入
echo "请输入您的名字:"
read name
echo "您好, $name!"

# 读取多个变量
echo "请输入您的姓名和年龄(用空格分隔):"
read first_name last_name age
echo "您好, $first_name $last_name! 您今年 $age 岁。"

# 读取密码（不显示输入）
echo "请输入密码:"
read -s password
echo "密码已接收"

# 带提示的读取
read -p "请输入您的邮箱: " email
echo "您的邮箱是: $email"

# 带超时的读取
read -t 5 -p "请在5秒内输入内容: " input
echo "您输入的是: $input"

# 重定向标准输出
echo "这是一条消息" > output.txt
echo "这是另一条消息" >> output.txt  # 追加到文件

# 重定向标准错误
echo "这是一条错误消息" >&2

# 将标准错误重定向到文件
ls /nonexistent 2> error.log
```

### 文件操作

```bash
#!/bin/bash
# 文件操作示例

# 创建目录
mkdir -p temp/subdir

# 检查文件是否存在
file_path="example.txt"
if [ ! -f "$file_path" ]; then
    echo "创建文件: $file_path"
    touch "$file_path"
else
    echo "文件已存在"
fi

# 写入文件
echo "这是第一行" > "$file_path"
echo "这是第二行" >> "$file_path"

# 读取文件内容并显示
echo "文件内容:"
cat "$file_path"

# 逐行读取文件
echo "逐行处理文件:"
while IFS= read -r line; do
    echo ">> $line"
done < "$file_path"

# 处理CSV文件
echo "name,age,city" > data.csv
echo "张三,25,北京" >> data.csv
echo "李四,30,上海" >> data.csv

echo "CSV文件内容:"
while IFS=, read -r name age city; do
    echo "姓名: $name, 年龄: $age, 城市: $city"
done < data.csv

# 文件属性
echo "文件信息:"
file_info=$(ls -l "$file_path")
echo "$file_info"

# 删除文件
rm "$file_path"
rm data.csv
rm -rf temp
```

## Bash 进阶与实战

### 错误处理与退出状态

```bash
#!/bin/bash
# 错误处理示例

# 检查上一条命令是否成功
ls /etc/passwd
if [ $? -eq 0 ]; then
    echo "命令执行成功"
else
    echo "命令执行失败"
fi

# 使用 || 操作符在命令失败时执行动作
ls /nonexistent || echo "文件不存在"

# 使用 && 操作符在命令成功时执行动作
ls /etc/passwd && echo "文件存在"

# 设置错误退出
set -e  # 脚本中任何命令失败都会导致脚本退出

# 退出脚本
echo "正常退出"
exit 0

echo "这行不会执行"
exit 1  # 错误退出
```

### 正则表达式与文本处理

```bash
#!/bin/bash
# 文本处理示例

# 创建一个示例日志文件
cat > sample.log << EOF
2023-01-01 10:15:23 INFO 服务启动成功
2023-01-01 10:16:45 WARNING 磁盘空间不足
2023-01-01 10:20:12 ERROR 数据库连接失败 [DB001]
2023-01-01 10:22:34 INFO 用户admin登录成功，IP: 192.168.1.100
2023-01-01 10:25:16 ERROR 权限校验失败 [SEC002]
EOF

# grep 基本使用
echo "包含 ERROR 的行:"
grep "ERROR" sample.log

# grep 使用正则表达式
echo "找出所有错误码:"
grep -o "\[.*\]" sample.log

# grep 统计匹配行数
error_count=$(grep -c "ERROR" sample.log)
echo "错误日志数量: $error_count"

# sed 替换文本
echo "将 ERROR 替换为 CRITICAL:"
sed 's/ERROR/CRITICAL/g' sample.log

# sed 删除行
echo "删除包含 WARNING 的行:"
sed '/WARNING/d' sample.log

# awk 处理结构化数据
echo "提取时间和日志级别:"
awk '{print $1, $2, $3}' sample.log

# awk 过滤并格式化输出
echo "格式化错误信息:"
awk '/ERROR/ {printf "错误(%s): %s\n", $1, substr($0, index($0,$4))}' sample.log

# awk 统计
echo "统计各日志级别数量:"
awk '{count[$3]++} END {for(level in count) print level, count[level]}' sample.log

# cut 提取列
echo "提取日志级别:"
cut -d' ' -f3 sample.log

# sort 和 uniq 处理
echo "排序并去重:"
cut -d' ' -f3 sample.log | sort | uniq -c
```

### 系统监控脚本

```bash
#!/bin/bash
# 系统监控脚本

log_file="system_monitor_$(date +%Y%m%d).log"

# 日志函数
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$log_file"
}

# 检查CPU使用率
check_cpu() {
    cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2 + $4}')
    log "CPU使用率: ${cpu_usage}%"

    if (( $(echo "$cpu_usage > 80" | bc -l) )); then
        log "警告: CPU使用率过高!"
    fi
}

# 检查内存使用
check_memory() {
    memory_info=$(free -m | grep Mem)
    total_mem=$(echo "$memory_info" | awk '{print $2}')
    used_mem=$(echo "$memory_info" | awk '{print $3}')
    mem_usage=$(awk "BEGIN {printf \"%.2f\", $used_mem*100/$total_mem}")

    log "内存使用: ${used_mem}MB/${total_mem}MB (${mem_usage}%)"

    if (( $(echo "$mem_usage > 80" | bc -l) )); then
        log "警告: 内存使用率过高!"
    fi
}

# 检查磁盘使用
check_disk() {
    disk_info=$(df -h / | grep -v Filesystem)
    disk_usage=$(echo "$disk_info" | awk '{print $5}' | tr -d '%')

    log "磁盘使用率: ${disk_usage}%"

    if [ "$disk_usage" -gt 80 ]; then
        log "警告: 磁盘使用率过高!"
    fi
}

# 检查进程数量
check_processes() {
    process_count=$(ps aux | wc -l)
    log "当前进程数: $process_count"
}

# 检查系统负载
check_load() {
    load_average=$(uptime | awk -F'load average:' '{print $2}' | tr -d ' ' | cut -d',' -f1)
    log "系统负载: $load_average"

    if (( $(echo "$load_average > 2" | bc -l) )); then
        log "警告: 系统负载过高!"
    fi
}

# 主函数
main() {
    log "=== 系统监控开始 ==="
    check_cpu
    check_memory
    check_disk
    check_processes
    check_load
    log "=== 系统监控结束 ===\n"
}

# 执行主函数
main

# 定时执行可以使用crontab
# */5 * * * * /path/to/system_monitor.sh
```

### 自动备份脚本

```bash
#!/bin/bash
# 数据库和配置文件自动备份脚本

# 配置
BACKUP_DIR="/backup"
DB_USER="dbuser"
DB_PASS="password"
DB_NAME="mydb"
CONFIG_DIR="/etc/myapp"
DATE=$(date +%Y%m%d_%H%M%S)
LOG_FILE="$BACKUP_DIR/backup_$DATE.log"
RETENTION_DAYS=7

# 确保备份目录存在
mkdir -p "$BACKUP_DIR"

# 日志函数
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

# 检查命令执行状态
check_status() {
    if [ $1 -eq 0 ]; then
        log "成功: $2"
    else
        log "错误: $2 失败"
        exit 1
    fi
}

# 备份数据库
backup_database() {
    log "开始备份数据库 $DB_NAME..."
    DB_BACKUP_FILE="$BACKUP_DIR/db_${DB_NAME}_$DATE.sql.gz"

    if command -v mysqldump &> /dev/null; then
        mysqldump -u "$DB_USER" -p"$DB_PASS" "$DB_NAME" | gzip > "$DB_BACKUP_FILE"
        check_status $? "数据库备份"
    else
        log "错误: mysqldump 命令未找到"
        exit 1
    fi
}

# 备份配置文件
backup_configs() {
    log "开始备份配置文件..."
    CONFIG_BACKUP_FILE="$BACKUP_DIR/config_$DATE.tar.gz"

    tar -czf "$CONFIG_BACKUP_FILE" "$CONFIG_DIR"
    check_status $? "配置文件备份"
}

# 清理旧备份
cleanup_old_backups() {
    log "清理 $RETENTION_DAYS 天前的备份文件..."
    find "$BACKUP_DIR" -name "*.gz" -type f -mtime +$RETENTION_DAYS -delete
    check_status $? "清理旧备份"
}

# 主函数
main() {
    log "=== 开始备份过程 ==="
    backup_database
    backup_configs
    cleanup_old_backups
    log "=== 备份过程完成 ===\n"
}

# 执行主函数
main

# 定时执行可以使用crontab
# 0 2 * * * /path/to/backup.sh
```

### 日志分析脚本

```bash
#!/bin/bash
# 日志分析脚本

# 配置
LOG_FILE="/var/log/apache2/access.log"
OUTPUT_DIR="./log_reports"
DATE=$(date +%Y%m%d)

# 确保输出目录存在
mkdir -p "$OUTPUT_DIR"

# 检查日志文件是否存在
if [ ! -f "$LOG_FILE" ]; then
    echo "错误: 找不到日志文件 $LOG_FILE"
    exit 1
fi

# 1. 统计访问次数最多的IP地址
echo "分析访问频率最高的IP地址..."
top_ips_file="$OUTPUT_DIR/top_ips_$DATE.txt"
awk '{print $1}' "$LOG_FILE" | sort | uniq -c | sort -nr | head -10 > "$top_ips_file"
echo "完成! 结果保存在 $top_ips_file"

# 2. 统计访问最多的页面
echo "分析访问最多的URL..."
top_urls_file="$OUTPUT_DIR/top_urls_$DATE.txt"
awk '{print $7}' "$LOG_FILE" | sort | uniq -c | sort -nr | head -10 > "$top_urls_file"
echo "完成! 结果保存在 $top_urls_file"

# 3. 统计HTTP状态码
echo "分析HTTP状态码分布..."
http_status_file="$OUTPUT_DIR/http_status_$DATE.txt"
awk '{print $9}' "$LOG_FILE" | sort | uniq -c | sort -nr > "$http_status_file"
echo "完成! 结果保存在 $http_status_file"

# 4. 分析每小时的请求量
echo "分析每小时请求量..."
hourly_requests_file="$OUTPUT_DIR/hourly_requests_$DATE.txt"
awk '{print substr($4, 14, 2)}' "$LOG_FILE" | sort | uniq -c > "$hourly_requests_file"
echo "完成! 结果保存在 $hourly_requests_file"

# 5. 检测可能的恶意请求
echo "检测潜在的恶意请求..."
suspicious_requests_file="$OUTPUT_DIR/suspicious_requests_$DATE.txt"
grep -i "script\|eval\|alert\|javascript\|%3C\|%3E" "$LOG_FILE" > "$suspicious_requests_file"
echo "完成! 结果保存在 $suspicious_requests_file"

# 6. 检测404错误
echo "检测404错误..."
not_found_file="$OUTPUT_DIR/404_errors_$DATE.txt"
grep " 404 " "$LOG_FILE" | awk '{print $7}' | sort | uniq -c | sort -nr > "$not_found_file"
echo "完成! 结果保存在 $not_found_file"

# 7. 计算日志大小
log_size=$(du -h "$LOG_FILE" | cut -f1)
echo "日志文件大小: $log_size"

# 8. 生成摘要报告
summary_file="$OUTPUT_DIR/summary_$DATE.txt"
{
    echo "=== 日志分析摘要 ($(date)) ==="
    echo "日志文件: $LOG_FILE"
    echo "文件大小: $log_size"
    echo ""
    echo "总请求数: $(wc -l < "$LOG_FILE")"
    echo "独立IP数: $(awk '{print $1}' "$LOG_FILE" | sort -u | wc -l)"
    echo "成功请求(2xx): $(grep -c ' 2[0-9][0-9] ' "$LOG_FILE")"
    echo "重定向(3xx): $(grep -c ' 3[0-9][0-9] ' "$LOG_FILE")"
    echo "客户端错误(4xx): $(grep -c ' 4[0-9][0-9] ' "$LOG_FILE")"
    echo "服务器错误(5xx): $(grep -c ' 5[0-9][0-9] ' "$LOG_FILE")"
    echo ""
    echo "前5个访问IP:"
    head -5 "$top_ips_file"
    echo ""
    echo "前5个访问URL:"
    head -5 "$top_urls_file"
} > "$summary_file"

echo "摘要报告已保存到 $summary_file"
```

## Python 脚本基础

### 初识 Python 脚本

```python
#!/usr/bin/env python3
# 第一个Python脚本

# 基本输出
print("Hello, World!")

# 导入模块
import os
import sys
from datetime import datetime

# 获取当前时间
current_time = datetime.now()
print(f"当前时间是: {current_time}")

# 获取系统信息
print(f"当前用户: {os.getlogin()}")
print(f"当前工作目录: {os.getcwd()}")
print(f"Python版本: {sys.version}")
print(f"平台信息: {sys.platform}")

# 执行系统命令
print("\n系统信息:")
os.system("uname -a")
```

保存为 `hello.py` 并执行：

```bash
chmod +x hello.py
./hello.py
# 或
python3 hello.py
```

### 变量与数据类型

```python
#!/usr/bin/env python3
# 变量与数据类型示例

# 基本数据类型
name = "小明"  # 字符串
age = 25       # 整数
height = 1.75  # 浮点数
is_student = True  # 布尔值

# 输出变量
print("基本数据类型:")
print(f"姓名: {name}, 类型: {type(name)}")
print(f"年龄: {age}, 类型: {type(age)}")
print(f"身高: {height}, 类型: {type(height)}")
print(f"是否学生: {is_student}, 类型: {type(is_student)}")

# 数据集合类型
# 列表 (可更改)
fruits = ["苹果", "香蕉", "橙子"]
print("\n列表示例:")
print(f"水果列表: {fruits}")
print(f"第一个水果: {fruits[0]}")
fruits.append("葡萄")
print(f"添加后的水果列表: {fruits}")

# 元组 (不可更改)
coordinates = (10.5, 20.8)
print("\n元组示例:")
print(f"坐标: {coordinates}")
print(f"X坐标: {coordinates[0]}")

# 字典 (键值对)
person = {
    "name": "小红",
    "age": 28,
    "city": "上海"
}
print("\n字典示例:")
print(f"个人信息: {person}")
print(f"姓名: {person['name']}")
person["job"] = "工程师"
print(f"添加职业后: {person}")

# 集合 (唯一元素的无序集合)
unique_numbers = {1, 2, 3, 3, 2, 1}
print("\n集合示例:")
print(f"唯一数字: {unique_numbers}")
```

### 控制流

```python
#!/usr/bin/env python3
# 控制流示例

# if-elif-else条件语句
print("条件语句示例:")
age = int(input("请输入您的年龄: "))

if age < 18:
    print("您是未成年人")
elif age >= 18 and age < 60:
    print("您是成年人")
else:
    print("您是老年人")

# for循环
print("\nfor循环示例:")
print("遍历列表:")
fruits = ["苹果", "香蕉", "橙子"]
for fruit in fruits:
    print(f"- {fruit}")

print("\n遍历字典:")
person = {"name": "小明", "age": 25, "city": "北京"}
for key, value in person.items():
    print(f"- {key}: {value}")

print("\n遍历数字范围:")
for i in range(1, 6):  # 1到5
    print(f"数字: {i}")

# while循环
print("\nwhile循环示例:")
count = 1
while count <= 5:
    print(f"计数: {count}")
    count += 1

# break和continue
print("\nbreak示例:")
for i in range(1, 11):
    if i == 6:
        break
    print(f"数字: {i}")

print("\ncontinue示例:")
for i in range(1, 11):
    if i % 2 == 0:  # 跳过偶数
        continue
    print(f"数字: {i}")

# try-except异常处理
print("\n异常处理示例:")
try:
    number = int(input("请输入一个数字: "))
    result = 100 / number
    print(f"100 除以 {number} 等于 {result}")
except ValueError:
    print("输入错误！请输入一个有效的数字。")
except ZeroDivisionError:
    print("除数不能为零！")
except Exception as e:
    print(f"发生了其他错误: {e}")
finally:
    print("无论是否有异常，这里都会执行")
```

### 函数与模块

```python
#!/usr/bin/env python3
# 函数与模块示例

# 基本函数定义
def greet(name):
    """
    向指定的人打招呼

    参数:
    name (str): 人名

    返回:
    str: 问候语
    """
    return f"你好，{name}！"

# 带默认参数的函数
def calculate_area(length, width=1):
    """计算长方形面积"""
    return length * width

# 可变参数函数
def sum_all(*numbers):
    """计算所有数字的和"""
    return sum(numbers)

# 关键字可变参数
def create_profile(**details):
    """创建个人资料"""
    profile = {}
    for key, value in details.items():
        profile[key] = value
    return profile

# 调用函数
print(greet("小明"))
print(f"长方形面积: {calculate_area(5, 3)}")
print(f"正方形面积: {calculate_area(5)}")  # 使用默认参数
print(f"数字之和: {sum_all(1, 2, 3, 4, 5)}")
profile = create_profile(name="小红", age=28, city="上海", job="工程师")
print(f"个人资料: {profile}")

# 匿名函数 (lambda)
square = lambda x: x ** 2
print(f"5的平方: {square(5)}")

# 导入标准模块
import os
import sys
import math
from datetime import datetime
import random

# 使用标准库函数
print(f"\n当前工作目录: {os.getcwd()}")
print(f"π的值: {math.pi}")
print(f"当前时间: {datetime.now()}")
print(f"1到10的随机数: {random.randint(1, 10)}")

# 创建自己的模块
# 保存为utils.py
"""
def add(a, b):
    return a + b

def subtract(a, b):
    return a - b

def multiply(a, b):
    return a * b
"""

# 导入自定义模块
# import utils
# print(f"2+3={utils.add(2, 3)}")
```

### 文件操作

```python
#!/usr/bin/env python3
# 文件操作示例

# 写入文件
print("写入文件...")
with open('example.txt', 'w') as file:
    file.write("这是第一行\n")
    file.write("这是第二行\n")
    file.write("这是第三行\n")

# 读取整个文件
print("\n读取整个文件:")
with open('example.txt', 'r') as file:
    content = file.read()
    print(content)

# 逐行读取
print("\n逐行读取文件:")
with open('example.txt', 'r') as file:
    for line in file:
        print(f"> {line.strip()}")

# 读取特定行
print("\n读取特定行(第二行):")
with open('example.txt', 'r') as file:
    lines = file.readlines()
    if len(lines) >= 2:
        print(lines[1].strip())

# 追加到文件
print("\n向文件追加内容...")
with open('example.txt', 'a') as file:
    file.write("这是追加的第四行\n")

# 确认追加成功
print("\n追加后的文件内容:")
with open('example.txt', 'r') as file:
    content = file.read()
    print(content)

# 使用pathlib处理文件路径
from pathlib import Path

# 创建Path对象
file_path = Path('example.txt')
print(f"\n文件是否存在: {file_path.exists()}")
print(f"文件大小: {file_path.stat().st_size} 字节")
print(f"绝对路径: {file_path.absolute()}")

# 处理CSV文件
import csv

# 写入CSV文件
print("\n写入CSV文件...")
with open('data.csv', 'w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(['姓名', '年龄', '城市'])
    writer.writerow(['小明', 25, '北京'])
    writer.writerow(['小红', 28, '上海'])
    writer.writerow(['小李', 22, '广州'])

# 读取CSV文件
print("\n读取CSV文件:")
with open('data.csv', 'r', newline='') as file:
    reader = csv.reader(file)
    for row in reader:
        print(', '.join(row))

# 使用字典读写CSV
print("\n使用字典处理CSV文件...")
with open('data_dict.csv', 'w', newline='') as file:
    fieldnames = ['姓名', '年龄', '城市']
    writer = csv.DictWriter(file, fieldnames=fieldnames)

    writer.writeheader()
    writer.writerow({'姓名': '小明', '年龄': 25, '城市': '北京'})
    writer.writerow({'姓名': '小红', '年龄': 28, '城市': '上海'})

print("\n读取CSV字典:")
with open('data_dict.csv', 'r', newline='') as file:
    reader = csv.DictReader(file)
    for row in reader:
        print(f"{row['姓名']}({row['年龄']}岁) 来自 {row['城市']}")

# 清理示例文件
import os
print("\n清理示例文件...")
for file_name in ['example.txt', 'data.csv', 'data_dict.csv']:
    if os.path.exists(file_name):
        os.remove(file_name)
        print(f"已删除 {file_name}")
```

### 命令行参数与环境

```python
#!/usr/bin/env python3
# 命令行参数示例

import sys
import os
import argparse
from datetime import datetime

# 基本命令行参数处理
print("基本参数处理:")
print(f"脚本名称: {sys.argv[0]}")
print(f"参数个数: {len(sys.argv) - 1}")
print(f"所有参数: {sys.argv[1:]}")

# 使用argparse进行高级参数处理
parser = argparse.ArgumentParser(description='命令行参数示例')

# 添加参数选项
parser.add_argument('--name', type=str, default='用户', help='用户名')
parser.add_argument('--age', type=int, help='年龄')
parser.add_argument('--verbose', '-v', action='store_true', help='启用详细输出')
parser.add_argument('files', nargs='*', help='文件列表')

# 解析参数
args = parser.parse_args()

# 使用参数
print("\n参数解析结果:")
print(f"用户名: {args.name}")
print(f"年龄: {args.age}")
print(f"详细模式: {'开启' if args.verbose else '关闭'}")
print(f"文件列表: {args.files}")

# 环境变量
print("\n环境变量:")
print(f"HOME: {os.environ.get('HOME', '未设置')}")
print(f"USER: {os.environ.get('USER', '未设置')}")
print(f"PATH: {os.environ.get('PATH', '未设置')[:50]}...") # 只显示前50个字符

# 设置环境变量
os.environ['APP_ENV'] = 'development'
print(f"自定义环境变量APP_ENV: {os.environ.get('APP_ENV')}")

# 获取系统信息
print("\n系统信息:")
print(f"操作系统: {sys.platform}")
print(f"Python版本: {sys.version}")
print(f"当前时间: {datetime.now()}")
print(f"CPU数量: {os.cpu_count()}")
```

### 进程与命令执行

```python
#!/usr/bin/env python3
# 进程和命令执行示例

import os
import sys
import subprocess
import time
import signal

# 获取当前进程信息
print(f"当前进程ID: {os.getpid()}")
print(f"父进程ID: {os.getppid()}")

# 使用os.system执行命令 (简单但功能有限)
print("\nos.system示例:")
os.system("echo '使用os.system执行命令'")
os.system("ls -la | head -5")

# 使用subprocess执行命令 (推荐方式)
print("\nsubprocess.run示例:")
result = subprocess.run(["ls", "-la"], capture_output=True, text=True)
print(f"返回码: {result.returncode}")
print(f"输出的前3行:\n{'.'.join(result.stdout.splitlines()[:3])}")

# 管道和复杂命令
print("\n管道命令示例:")
ps_process = subprocess.run("ps aux | grep python | grep -v grep", 
                           shell=True, capture_output=True, text=True)
print(ps_process.stdout)

# 创建子进程并获取输出
print("\n实时获取命令输出:")
process = subprocess.Popen(["ping", "-c", "4", "127.0.0.1"], 
                          stdout=subprocess.PIPE, text=True)

while True:
    output = process.stdout.readline()
    if output == '' and process.poll() is not None:
        break
    if output:
        print(output.strip())

# 使用communicate获取输出
print("\n使用communicate执行命令:")
process = subprocess.Popen(["echo", "Hello from subprocess"], 
                          stdout=subprocess.PIPE, text=True)
stdout, stderr = process.communicate()
print(f"输出: {stdout.strip()}")

# 执行外部脚本
print("\n执行脚本并传递参数:")
with open("temp_script.sh", "w") as f:
    f.write("""#!/bin/bash
echo "脚本收到的参数: $@"
echo "当前目录是: $(pwd)"
exit 0
""")

os.chmod("temp_script.sh", 0o755)  # 添加执行权限
result = subprocess.run(["./temp_script.sh", "arg1", "arg2"], 
                        capture_output=True, text=True)
print(result.stdout)

# 优雅地处理信号
def signal_handler(sig, frame):
    print('\n收到信号', sig)
    print('清理资源并退出')
    # 在这里执行清理代码
    os.remove("temp_script.sh")  # 删除临时脚本
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)
print("\n按Ctrl+C来触发信号处理器 (等待3秒后自动继续)")
try:
    time.sleep(3)
except KeyboardInterrupt:
    pass  # 信号处理器会处理这个

# 清理
if os.path.exists("temp_script.sh"):
    os.remove("temp_script.sh")
```

## Python 进阶与实战

### 系统监控脚本

```python
#!/usr/bin/env python3
# 系统监控脚本

import os
import sys
import psutil
import platform
import socket
import datetime
import time
import argparse
import logging

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("system_monitor.log"),
        logging.StreamHandler()
    ]
)

def get_size(bytes, suffix="B"):
    """
    将字节转换为可读格式 (KB, MB, GB, ...)
    """
    factor = 1024
    for unit in ["", "K", "M", "G", "T", "P"]:
        if bytes < factor:
            return f"{bytes:.2f}{unit}{suffix}"
        bytes /= factor

def get_system_info():
    """获取系统基本信息"""
    info = {}
    info["系统平台"] = platform.system()
    info["系统名称"] = platform.node()
    info["系统版本"] = platform.version()
    info["处理器"] = platform.processor()
    info["Python版本"] = platform.python_version()

    # 获取IP地址
    try:
        hostname = socket.gethostname()
        info["主机名"] = hostname
        info["IP地址"] = socket.gethostbyname(hostname)
    except Exception as e:
        info["IP地址"] = f"获取失败: {e}"

    return info

def get_cpu_info():
    """获取CPU信息"""
    info = {}
    info["物理核心数"] = psutil.cpu_count(logical=False)
    info["逻辑核心数"] = psutil.cpu_count(logical=True)

    # CPU使用率
    cpu_percent = psutil.cpu_percent(interval=1)
    info["总体使用率"] = f"{cpu_percent}%"

    # 各核心使用率
    per_cpu = psutil.cpu_percent(interval=1, percpu=True)
    for i, percent in enumerate(per_cpu):
        info[f"核心 {i} 使用率"] = f"{percent}%"

    return info

def get_memory_info():
    """获取内存使用情况"""
    info = {}
    vm = psutil.virtual_memory()

    info["总内存"] = get_size(vm.total)
    info["可用内存"] = get_size(vm.available)
    info["已用内存"] = get_size(vm.used)
    info["使用率"] = f"{vm.percent}%"

    # 交换内存
    swap = psutil.swap_memory()
    info["交换总量"] = get_size(swap.total)
    info["交换已用"] = get_size(swap.used)
    info["交换率"] = f"{swap.percent}%"

    return info

def get_disk_info():
    """获取磁盘信息"""
    info = {}
    partitions = psutil.disk_partitions()

    for i, partition in enumerate(partitions):
        try:
            partition_usage = psutil.disk_usage(partition.mountpoint)
            info[f"分区{i} - 挂载点"] = partition.mountpoint
            info[f"分区{i} - 总大小"] = get_size(partition_usage.total)
            info[f"分区{i} - 已使用"] = get_size(partition_usage.used)
            info[f"分区{i} - 剩余"] = get_size(partition_usage.free)
            info[f"分区{i} - 使用率"] = f"{partition_usage.percent}%"
            info[f"分区{i} - 文件系统"] = partition.fstype
        except Exception as e:
            info[f"分区{i} - 错误"] = str(e)

    # 总的IO统计
    io = psutil.disk_io_counters()
    if io:
        info["总读取"] = get_size(io.read_bytes)
        info["总写入"] = get_size(io.write_bytes)

    return info

def get_network_info():
    """获取网络信息"""
    info = {}

    # 获取网络接口信息
    if_addrs = psutil.net_if_addrs()
    for interface_name, interface_addresses in if_addrs.items():
        for address in interface_addresses:
            if str(address.family) == 'AddressFamily.AF_INET':
                info[f"{interface_name} - IPv4"] = address.address
            elif str(address.family) == 'AddressFamily.AF_INET6':
                info[f"{interface_name} - IPv6"] = address.address

    # 获取网络IO统计
    net_io = psutil.net_io_counters()
    info["总发送"] = get_size(net_io.bytes_sent)
    info["总接收"] = get_size(net_io.bytes_recv)

    return info

def get_process_info(top_n=5):
    """获取进程信息"""
    info = {}

    # 获取所有进程
    processes = []
    for proc in psutil.process_iter(['pid', 'name', 'username', 'cpu_percent', 'memory_percent']):
        try:
            proc.cpu_percent()  # 第一次调用总是返回0，所以先调用一次
        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
            pass

    # 等待一秒以获取真实CPU使用率
    time.sleep(1)

    for proc in psutil.process_iter(['pid', 'name', 'username', 'cpu_percent', 'memory_percent']):
        try:
            proc_info = proc.info
            processes.append(proc_info)
        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
            pass

    # 按CPU使用率排序，获取前top_n个
    top_cpu = sorted(processes, key=lambda p: p['cpu_percent'], reverse=True)[:top_n]
    for i, proc in enumerate(top_cpu):
        info[f"CPU-{i+1}"] = f"{proc['name']} (PID: {proc['pid']}, CPU: {proc['cpu_percent']}%)"

    # 按内存使用率排序，获取前top_n个
    top_mem = sorted(processes, key=lambda p: p['memory_percent'], reverse=True)[:top_n]
    for i, proc in enumerate(top_mem):
        info[f"MEM-{i+1}"] = f"{proc['name']} (PID: {proc['pid']}, MEM: {proc['memory_percent']:.2f}%)"

    return info

def print_section(title, data):
    """格式化打印某个部分的数据"""
    logging.info("=" * 50)
    logging.info(title)
    logging.info("=" * 50)

    for key, value in data.items():
        logging.info(f"{key}: {value}")
    logging.info("")

def monitor_once():
    """执行一次系统监控"""
    logging.info("\n" + "#" * 70)
    logging.info(f"系统监控报告 - {datetime.datetime.now()}")
    logging.info("#" * 70 + "\n")

    # 获取各种系统信息
    print_section("系统信息", get_system_info())
    print_section("CPU信息", get_cpu_info())
    print_section("内存信息", get_memory_info())
    print_section("磁盘信息", get_disk_info())
    print_section("网络信息", get_network_info())
    print_section("进程信息 (Top 5)", get_process_info(5))

    # 检查警告条件
    check_warnings()

def check_warnings():
    """检查系统资源警告条件"""
    warnings = []

    # CPU使用率高于80%则警告
    cpu_percent = psutil.cpu_percent()
    if cpu_percent > 80:
        warnings.append(f"CPU使用率过高: {cpu_percent}%")

    # 内存使用率高于80%则警告
    mem = psutil.virtual_memory()
    if mem.percent > 80:
        warnings.append(f"内存使用率过高: {mem.percent}%")

    # 磁盘空间低于20%则警告
    for part in psutil.disk_partitions():
        try:
            usage = psutil.disk_usage(part.mountpoint)
            if usage.percent > 80:
                warnings.append(f"磁盘空间不足 ({part.mountpoint}): 已使用 {usage.percent}%")
        except:
            pass

    # 输出警告
    if warnings:
        logging.warning("系统警告:")
        for warning in warnings:
            logging.warning(f"- {warning}")
    else:
        logging.info("系统状态正常，未发现警告")

def monitor_continuous(interval=60):
    """定期执行系统监控"""
    try:
        while True:
            monitor_once()
            time.sleep(interval)
    except KeyboardInterrupt:
        logging.info("监控程序被用户中断")

def main():
    parser = argparse.ArgumentParser(description='系统监控工具')
    parser.add_argument('-o', '--once', action='store_true', help='只执行一次监控')
    parser.add_argument('-i', '--interval', type=int, default=60, 
                        help='连续监控的时间间隔(秒)')
    args = parser.parse_args()

    if args.once:
        monitor_once()
    else:
        logging.info(f"开始连续监控系统，间隔: {args.interval}秒 (按Ctrl+C停止)")
        monitor_continuous(args.interval)

if __name__ == "__main__":
    # 检查必要的依赖
    if not 'psutil' in sys.modules:
        print("请先安装psutil模块: pip install psutil")
        sys.exit(1)

    main()
```

### 网络监控和通知脚本

```python
#!/usr/bin/env python3
# 网络监控与通知脚本

import os
import sys
import time
import socket
import smtplib
import argparse
import logging
import subprocess
import platform
import json
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime, timedelta

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("network_monitor.log"),
        logging.StreamHandler()
    ]
)

# 默认配置
DEFAULT_CONFIG = {
    "hosts": [
        {"name": "Google DNS", "address": "8.8.8.8", "type": "ping"},
        {"name": "Local Router", "address": "192.168.1.1", "type": "ping"},
        {"name": "Web Server", "address": "example.com", "port": 80, "type": "tcp"}
    ],
    "intervals": {
        "check": 300,  # 5分钟检查一次
        "alert": 1800  # 同一问题30分钟内不重复发送警报
    },
    "thresholds": {
        "ping_timeout": 2,  # 秒
        "tcp_timeout": 5,  # 秒
        "packet_loss": 50  # 丢包率百分比
    },
    "email": {
        "enabled": False,
        "server": "smtp.gmail.com",
        "port": 587,
        "use_tls": True,
        "username": "your_email@gmail.com",
        "password": "your_password",
        "from": "your_email@gmail.com",
        "to": ["recipient@example.com"]
    }
}

# 状态跟踪
host_status = {}
last_alerts = {}

def load_config(config_file=None):
    """加载配置文件，如果不存在则使用默认配置"""
    config = DEFAULT_CONFIG.copy()

    if config_file and os.path.exists(config_file):
        try:
            with open(config_file, 'r') as f:
                user_config = json.load(f)
                # 合并配置
                for key, value in user_config.items():
                    if key in config:
                        if isinstance(config[key], dict) and isinstance(value, dict):
                            config[key].update(value)
                        else:
                            config[key] = value
            logging.info(f"已从 {config_file} 加载配置")
        except Exception as e:
            logging.error(f"加载配置文件出错: {e}")
            logging.info("使用默认配置")
    else:
        logging.info("使用默认配置")

    return config

def ping_host(host, timeout):
    """
    使用ICMP ping测试主机连通性
    返回: (是否成功, 丢包率, 延迟)
    """
    param = '-n' if platform.system().lower() == 'windows' else '-c'
    command = ['ping', param, '4', '-W', str(timeout), host]

    try:
        output = subprocess.check_output(command, stderr=subprocess.STDOUT, universal_newlines=True)

        # 解析输出
        if platform.system().lower() == 'windows':
            packet_loss_line = [l for l in output.split('\n') if 'Lost' in l][0]
            packet_loss = int(packet_loss_line.split('(')[1].split('%')[0])

            if '最小 = ' in output:  # 中文Windows
                time_line = [l for l in output.split('\n') if '最小 = ' in l][0]
                avg_time = float(time_line.split('平均 = ')[1].split('ms')[0])
            elif 'Minimum = ' in output:  # 英文Windows
                time_line = [l for l in output.split('\n') if 'Minimum = ' in l][0]
                avg_time = float(time_line.split('Average = ')[1].split('ms')[0])
            else:
                avg_time = 0
        else:
            packet_loss_line = [l for l in output.split('\n') if 'packet loss' in l][0]
            packet_loss = int(packet_loss_line.split('%')[0].split(' ')[-1])

            if '/' in output and 'avg' in output:
                time_line = [l for l in output.split('\n') if 'min/avg/max' in l][0]
                avg_time = float(time_line.split('/')[4].split('/')[0])
            else:
                avg_time = 0

        success = packet_loss < 100
        return success, packet_loss, avg_time
    except subprocess.CalledProcessError:
        return False, 100, 0
    except Exception as e:
        logging.error(f"Ping {host} 错误: {e}")
        return False, 100, 0

def check_tcp_port(host, port, timeout):
    """
    检查TCP端口是否可连接
    返回: (是否成功, 连接时间)
    """
    start_time = time.time()
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        result = sock.connect_ex((host, port))
        elapsed_time = (time.time() - start_time) * 1000  # 毫秒
        sock.close()

        if result == 0:
            return True, elapsed_time
        else:
            return False, 0
    except socket.gaierror:
        logging.error(f"无法解析主机名: {host}")
        return False, 0
    except socket.error as e:
        logging.error(f"连接 {host}:{port} 错误: {e}")
        return False, 0

def send_email_alert(config, subject, message):
    """发送邮件警报"""
    if not config['email']['enabled']:
        logging.info("邮件通知未启用")
        return False

    try:
        msg = MIMEMultipart()
        msg['From'] = config['email']['from']
        msg['To'] = ', '.join(config['email']['to'])
        msg['Subject'] = subject

        msg.attach(MIMEText(message, 'plain'))

        server = smtplib.SMTP(config['email']['server'], config['email']['port'])
        if config['email']['use_tls']:
            server.starttls()

        if config['email']['username'] and config['email']['password']:
            server.login(config['email']['username'], config['email']['password'])

        server.send_message(msg)
        server.quit()
        logging.info(f"已发送警报邮件: {subject}")
        return True
    except Exception as e:
        logging.error(f"发送邮件失败: {e}")
        return False

def check_host(host_config, config):
    """检查单个主机的状态"""
    name = host_config['name']
    address = host_config['address']
    host_type = host_config['type']
    result = False
    packet_loss = 100
    response_time = 0

    if host_type == 'ping':
        result, packet_loss, response_time = ping_host(
            address, config['thresholds']['ping_timeout'])
    elif host_type == 'tcp':
        port = host_config['port']
        result, response_time = check_tcp_port(
            address, port, config['thresholds']['tcp_timeout'])

    # 更新状态
    status = {
        'online': result,
        'last_check': datetime.now(),
        'packet_loss': packet_loss,
        'response_time': response_time
    }

    # 检查状态变化
    previous_status = host_status.get(name, {'online': None})
    status_changed = previous_status['online'] != result
    host_status[name] = status

    # 生成消息
    message = ""
    if host_type == 'ping':
        target = f"{address}"
        if result:
            message = f"{name} ({target}) 可访问，响应时间: {response_time:.2f}ms, 丢包率: {packet_loss}%"
        else:
            message = f"{name} ({target}) 不可访问，丢包率: {packet_loss}%"
    elif host_type == 'tcp':
        target = f"{address}:{host_config['port']}"
        if result:
            message = f"{name} ({target}) 端口开放，响应时间: {response_time:.2f}ms"
        else:
            message = f"{name} ({target}) 端口关闭或不可达"

    # 记录和发送警报
    if result:
        logging.info(message)
    else:
        logging.warning(message)

        # 检查是否应该发送警报
        should_alert = False
        if status_changed and not result:  # 只有从在线变为离线时才发送警报
            should_alert = True
        elif not result:  # 如果持续离线，检查是否已经超过了警报间隔
            last_alert_time = last_alerts.get(name, datetime.min)
            time_since_last_alert = datetime.now() - last_alert_time
            if time_since_last_alert > timedelta(seconds=config['intervals']['alert']):
                should_alert = True

        if should_alert:
            alert_subject = f"网络监控警报: {name} 不可访问"
            alert_message = f"""
网络监控检测到问题:

主机: {name}
地址: {address + (f':{host_config["port"]}' if host_type == 'tcp' else '')}
状态: {'在线' if result else '离线'}
响应时间: {response_time:.2f}ms
丢包率: {packet_loss}% (适用于ping)
检查时间: {status['last_check']}
            """

            if send_email_alert(config, alert_subject, alert_message):
                last_alerts[name] = datetime.now()

    return result

def monitor_network(config):
    """监控所有配置的主机"""
    all_hosts_ok = True

    logging.info(f"开始检查 {len(config['hosts'])} 个主机...")
    for host in config['hosts']:
        host_ok = check_host(host, config)
    all_hosts_ok = all_hosts_ok and host_ok

    if all_hosts_ok:
        logging.info("所有主机检查正常")
    else:
        logging.warning("部分主机检查失败，请查看日志获取详细信息")

    return all_hosts_ok

def continuous_monitoring(config):
    """持续监控主机状态"""
    try:
        while True:
            logging.info(f"\n--- 网络监控检查 {datetime.now()} ---")
            monitor_network(config)
            time.sleep(config['intervals']['check'])
    except KeyboardInterrupt:
        logging.info("监控被用户中断")

def main():
    parser = argparse.ArgumentParser(description='网络监控与通知脚本')
    parser.add_argument('-c', '--config', help='配置文件路径')
    parser.add_argument('-o', '--once', action='store_true', help='仅执行一次检查')
    args = parser.parse_args()

    # 加载配置
    config = load_config(args.config)

    if args.once:
        monitor_network(config)
    else:
        logging.info(f"开始持续监控，检查间隔: {config['intervals']['check']}秒")
        continuous_monitoring(config)

if __name__ == "__main__":
    main()
```

### 自动化文件管理与清理脚本

```python
#!/usr/bin/env python3
# 自动化文件管理与清理脚本

import os
import sys
import shutil
import argparse
import logging
import time
from datetime import datetime, timedelta
import re
import hashlib
import mimetypes
from pathlib import Path

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("file_manager.log"),
        logging.StreamHandler()
    ]
)

def get_file_info(file_path):
    """获取文件的详细信息"""
    file_path = Path(file_path)
    stats = file_path.stat()

    # 判断文件类型
    mime_type, _ = mimetypes.guess_type(file_path)
    if mime_type is None:
        if file_path.is_dir():
            file_type = "directory"
        else:
            file_type = "unknown"
    else:
        file_type = mime_type

    return {
        "name": file_path.name,
        "path": str(file_path),
        "size": stats.st_size,
        "size_human": get_human_size(stats.st_size),
        "created": datetime.fromtimestamp(stats.st_ctime),
        "modified": datetime.fromtimestamp(stats.st_mtime),
        "accessed": datetime.fromtimestamp(stats.st_atime),
        "type": file_type,
        "extension": file_path.suffix.lower() if file_path.suffix else "",
    }

def get_human_size(size_bytes):
    """将字节大小转换为人类可读格式"""
    if size_bytes == 0:
        return "0B"

    size_names = ("B", "KB", "MB", "GB", "TB", "PB", "EB", "ZB", "YB")
    i = int(math.floor(math.log(size_bytes, 1024)))
    p = math.pow(1024, i)
    s = round(size_bytes / p, 2)

    return f"{s} {size_names[i]}"

def calculate_md5(file_path):
    """计算文件的MD5哈希值"""
    hash_md5 = hashlib.md5()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()

def find_files(directory, patterns=None, recursive=True, min_age=None, max_age=None, min_size=None, max_size=None):
    """
    查找符合条件的文件

    参数:
    directory - 要搜索的目录
    patterns - 文件名模式列表 (正则表达式)
    recursive - 是否递归搜索子目录
    min_age - 最小文件年龄 (天)
    max_age - 最大文件年龄 (天)
    min_size - 最小文件大小 (字节)
    max_size - 最大文件大小 (字节)

    返回: 符合条件的文件列表
    """
    matched_files = []
    now = datetime.now()

    # 编译正则表达式
    compiled_patterns = []
    if patterns:
        for pattern in patterns:
            try:
                compiled_patterns.append(re.compile(pattern))
            except re.error as e:
                logging.error(f"无效的正则表达式 '{pattern}': {e}")

    # 搜索文件
    for root, dirs, files in os.walk(directory):
        for file in files:
            file_path = os.path.join(root, file)

            # 获取文件信息
            try:
                stats = os.stat(file_path)
            except OSError as e:
                logging.warning(f"无法获取文件信息 '{file_path}': {e}")
                continue

            # 检查文件是否符合条件
            # 1. 检查文件名模式
            if compiled_patterns:
                name_matched = False
                for pattern in compiled_patterns:
                    if pattern.search(file):
                        name_matched = True
                        break
                if not name_matched:
                    continue

            # 2. 检查文件年龄
            file_age = (now - datetime.fromtimestamp(stats.st_mtime)).days
            if min_age is not None and file_age < min_age:
                continue
            if max_age is not None and file_age > max_age:
                continue

            # 3. 检查文件大小
            file_size = stats.st_size
            if min_size is not None and file_size < min_size:
                continue
            if max_size is not None and file_size > max_size:
                continue

            # 文件符合所有条件
            matched_files.append(file_path)

        # 如果不递归，则跳出循环
        if not recursive:
            break

    return matched_files

def organize_files(directory, rules, dry_run=False):
    """
    根据规则整理文件

    参数:
    directory - 要整理的目录
    rules - 整理规则列表，每条规则包含pattern和target_dir
    dry_run - 如果为True，则只显示将要执行的操作，不实际移动文件

    返回: 移动的文件计数
    """
    moved_count = 0

    for rule in rules:
        if 'pattern' not in rule or 'target_dir' not in rule:
            logging.error(f"无效的规则: {rule}")
            continue

        pattern = rule['pattern']
        target_dir = rule['target_dir']

        # 确保目标目录存在
        if not dry_run and not os.path.exists(target_dir):
            try:
                os.makedirs(target_dir)
                logging.info(f"创建目录: {target_dir}")
            except OSError as e:
                logging.error(f"无法创建目录 '{target_dir}': {e}")
                continue

        # 查找匹配的文件
        matched_files = find_files(directory, [pattern], recursive=True)

        # 移动文件
        for file_path in matched_files:
            file_name = os.path.basename(file_path)
            dest_path = os.path.join(target_dir, file_name)

            # 检查目标文件是否已存在
            if os.path.exists(dest_path):
                base, ext = os.path.splitext(file_name)
                dest_path = os.path.join(target_dir, f"{base}_{int(time.time())}{ext}")

            if dry_run:
                logging.info(f"[演习] 移动: {file_path} -> {dest_path}")
            else:
                try:
                    shutil.move(file_path, dest_path)
                    logging.info(f"移动: {file_path} -> {dest_path}")
                    moved_count += 1
                except OSError as e:
                    logging.error(f"移动文件失败 '{file_path}': {e}")

    return moved_count

def cleanup_old_files(directory, age_days, patterns=None, recursive=True, dry_run=False):
    """
    清理指定目录中的旧文件

    参数:
    directory - 要清理的目录
    age_days - 文件年龄阈值 (天)
    patterns - 文件名模式列表 (正则表达式)
    recursive - 是否递归清理子目录
    dry_run - 如果为True，则只显示将要删除的文件，不实际删除

    返回: 删除的文件计数和节省的空间 (字节)
    """
    deleted_count = 0
    saved_space = 0

    # 查找要删除的文件
    old_files = find_files(directory, patterns, recursive, min_age=age_days)

    # 删除文件
    for file_path in old_files:
        try:
            file_size = os.path.getsize(file_path)
            if dry_run:
                logging.info(f"[演习] 删除: {file_path} ({get_human_size(file_size)})")
            else:
                os.remove(file_path)
                logging.info(f"删除: {file_path} ({get_human_size(file_size)})")
                deleted_count += 1
                saved_space += file_size
        except OSError as e:
            logging.error(f"删除文件失败 '{file_path}': {e}")

    return deleted_count, saved_space

def find_duplicates(directory, recursive=True):
    """
    查找指定目录中的重复文件

    参数:
    directory - 要搜索的目录
    recursive - 是否递归搜索子目录

    返回: 重复文件组的字典 {哈希值: [文件路径列表]}
    """
    file_hashes = {}
    duplicates = {}

    for root, dirs, files in os.walk(directory):
        for file in files:
            file_path = os.path.join(root, file)

            try:
                # 先检查文件大小，大小不同的文件肯定不重复
                file_size = os.path.getsize(file_path)

                # 计算文件哈希
                file_hash = calculate_md5(file_path)

                # 记录哈希和文件路径
                if file_hash in file_hashes:
                    if file_hash not in duplicates:
                        duplicates[file_hash] = [file_hashes[file_hash]]
                    duplicates[file_hash].append(file_path)
                else:
                    file_hashes[file_hash] = file_path
            except OSError as e:
                logging.warning(f"处理文件失败 '{file_path}': {e}")

        # 如果不递归，则跳出循环
        if not recursive:
            break

    return duplicates

def main():
    parser = argparse.ArgumentParser(description='文件管理与清理工具')

    subparsers = parser.add_subparsers(dest='command', help='命令')

    # find命令
    find_parser = subparsers.add_parser('find', help='查找文件')
    find_parser.add_argument('directory', help='要搜索的目录')
    find_parser.add_argument('--pattern', '-p', action='append', help='文件名模式 (正则表达式)')
    find_parser.add_argument('--recursive', '-r', action='store_true', default=True, help='递归搜索子目录')
    find_parser.add_argument('--min-age', type=int, help='最小文件年龄 (天)')
    find_parser.add_argument('--max-age', type=int, help='最大文件年龄 (天)')
    find_parser.add_argument('--min-size', type=int, help='最小文件大小 (字节)')
    find_parser.add_argument('--max-size', type=int, help='最大文件大小 (字节)')

    # organize命令
    organize_parser = subparsers.add_parser('organize', help='整理文件')
    organize_parser.add_argument('directory', help='要整理的目录')
    organize_parser.add_argument('--rules', '-r', required=True, help='整理规则JSON文件')
    organize_parser.add_argument('--dry-run', '-d', action='store_true', help='演习模式，不实际移动文件')

    # cleanup命令
    cleanup_parser = subparsers.add_parser('cleanup', help='清理旧文件')
    cleanup_parser.add_argument('directory', help='要清理的目录')
    cleanup_parser.add_argument('--age', '-a', type=int, required=True, help='文件年龄阈值 (天)')
    cleanup_parser.add_argument('--pattern', '-p', action='append', help='文件名模式 (正则表达式)')
    cleanup_parser.add_argument('--recursive', '-r', action='store_true', default=True, help='递归清理子目录')
    cleanup_parser.add_argument('--dry-run', '-d', action='store_true', help='演习模式，不实际删除文件')

    # duplicates命令
    duplicates_parser = subparsers.add_parser('duplicates', help='查找重复文件')
    duplicates_parser.add_argument('directory', help='要搜索的目录')
    duplicates_parser.add_argument('--recursive', '-r', action='store_true', default=True, help='递归搜索子目录')

    args = parser.parse_args()

    if args.command == 'find':
        files = find_files(
            args.directory,
            args.pattern,
            args.recursive,
            args.min_age,
            args.max_age,
            args.min_size,
            args.max_size
        )
        print(f"找到 {len(files)} 个匹配的文件:")
        for file in files:
            print(file)

    elif args.command == 'organize':
        try:
            with open(args.rules, 'r') as f:
                rules = json.load(f)

            moved_count = organize_files(args.directory, rules, args.dry_run)

            if args.dry_run:
                print(f"[演习] 将会移动 {moved_count} 个文件")
            else:
                print(f"已移动 {moved_count} 个文件")
        except Exception as e:
            logging.error(f"整理文件失败: {e}")

    elif args.command == 'cleanup':
        deleted_count, saved_space = cleanup_old_files(
            args.directory,
            args.age,
            args.pattern,
            args.recursive,
            args.dry_run
        )

        if args.dry_run:
            print(f"[演习] 将会删除 {deleted_count} 个文件，节省 {get_human_size(saved_space)} 空间")
        else:
            print(f"已删除 {deleted_count} 个文件，节省 {get_human_size(saved_space)} 空间")

    elif args.command == 'duplicates':
        duplicates = find_duplicates(args.directory, args.recursive)
        duplicate_count = sum(len(files) for files in duplicates.values())
        duplicate_groups = len(duplicates)

        print(f"找到 {duplicate_count} 个重复文件，分属于 {duplicate_groups} 个重复组:")
        for file_hash, files in duplicates.items():
            if len(files) > 1:
                size = os.path.getsize(files[0])
                print(f"\n重复组 (大小: {get_human_size(size)}, MD5: {file_hash}):")
                for file_path in files:
                    print(f"  - {file_path}")
    else:
        parser.print_help()

if __name__ == "__main__":
    import math
    import json
    main()
```

### 数据库备份与管理脚本

```python
#!/usr/bin/env python3
# 数据库备份与管理脚本

import os
import sys
import time
import argparse
import logging
import subprocess
import shutil
import json
import gzip
import tarfile
from datetime import datetime, timedelta
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("db_backup.log"),
        logging.StreamHandler()
    ]
)

class DatabaseBackup:
    def __init__(self, config_file=None):
        """初始化数据库备份类"""
        self.config = self._load_config(config_file)

    def _load_config(self, config_file):
        """加载配置文件"""
        default_config = {
            "backup_dir": "/var/backups/databases",
            "retention": {
                "days": 7,
                "weeks": 4,
                "months": 3
            },
            "compression": "gzip",
            "mysql": {
                "enabled": True,
                "host": "localhost",
                "port": 3306,
                "user": "backup_user",
                "password": "backup_password",
                "databases": ["all"],
                "options": "--single-transaction --routines --triggers --events"
            },
            "postgresql": {
                "enabled": False,
                "host": "localhost",
                "port": 5432,
                "user": "postgres",
                "password": "",
                "databases": ["all"],
                "options": "-c --if-exists"
            },
            "notification": {
                "enabled": False,
                "email": {
                    "server": "smtp.example.com",
                    "port": 587,
                    "use_tls": True,
                    "username": "user@example.com",
                    "password": "password",
                    "from": "backup@example.com",
                    "to": ["admin@example.com"]
                }
            }
        }

        config = default_config.copy()

        if config_file and os.path.exists(config_file):
            try:
                with open(config_file, 'r') as f:
                    user_config = json.load(f)

                # 递归合并配置
                def merge_configs(base, override):
                    for key, value in override.items():
                        if isinstance(value, dict) and key in base and isinstance(base[key], dict):
                            merge_configs(base[key], value)
                        else:
                            base[key] = value

                merge_configs(config, user_config)
                logging.info(f"已从 {config_file} 加载配置")
            except Exception as e:
                logging.error(f"加载配置文件失败: {e}")
                logging.info("使用默认配置")
        else:
            logging.info("使用默认配置")

        return config

    def _ensure_backup_dir(self, backup_type):
        """确保备份目录存在"""
        backup_dir = os.path.join(self.config['backup_dir'], backup_type)

        if not os.path.exists(backup_dir):
            try:
                os.makedirs(backup_dir)
                logging.info(f"已创建备份目录: {backup_dir}")
            except OSError as e:
                logging.error(f"创建备份目录失败: {e}")
                raise

        return backup_dir

    def _get_mysql_databases(self):
        """获取MySQL数据库列表"""
        db_config = self.config['mysql']

        if "all" in db_config['databases']:
            cmd = [
                "mysql",
                f"--host={db_config['host']}",
                f"--port={db_config['port']}",
                f"--user={db_config['user']}",
                f"--password={db_config['password']}",
                "-e", "SHOW DATABASES;"
            ]

            try:
                result = subprocess.run(cmd, capture_output=True, text=True)
                if result.returncode != 0:
                    logging.error(f"获取MySQL数据库列表失败: {result.stderr}")
                    return []

                databases = []
                for line in result.stdout.splitlines()[1:]:  # 跳过标题行
                    db_name = line.strip()
                    # 排除系统数据库
                    if db_name not in ['information_schema', 'performance_schema', 'mysql', 'sys']:
                        databases.append(db_name)

                return databases
            except Exception as e:
                logging.error(f"获取MySQL数据库列表时发生错误: {e}")
                return []
        else:
            return db_config['databases']

    def _get_postgresql_databases(self):
        """获取PostgreSQL数据库列表"""
        db_config = self.config['postgresql']

        if "all" in db_config['databases']:
            env = os.environ.copy()
            env["PGPASSWORD"] = db_config['password']

            cmd = [
                "psql",
                f"-h{db_config['host']}",
                f"-p{db_config['port']}",
                f"-U{db_config['user']}",
                "-d", "postgres",
                "-t", "-c", "SELECT datname FROM pg_database WHERE datistemplate = false;"
            ]

            try:
                result = subprocess.run(cmd, capture_output=True, text=True, env=env)
                if result.returncode != 0:
                    logging.error(f"获取PostgreSQL数据库列表失败: {result.stderr}")
                    return []

                databases = []
                for line in result.stdout.splitlines():
                    db_name = line.strip()
                    if db_name and db_name not in ['postgres', 'template0', 'template1']:
                        databases.append(db_name)

                return databases
            except Exception as e:
                logging.error(f"获取PostgreSQL数据库列表时发生错误: {e}")
                return []
        else:
            return db_config['databases']

    def backup_mysql(self):
        """备份MySQL数据库"""
        if not self.config['mysql']['enabled']:
            logging.info("MySQL备份功能未启用")
            return []

        backup_dir = self._ensure_backup_dir("mysql")
        db_config = self.config['mysql']
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        databases = self._get_mysql_databases()
        backup_files = []

        for db_name in databases:
            output_file = os.path.join(backup_dir, f"{db_name}_{timestamp}.sql")

            if self.config['compression'] == 'gzip':
                output_file += ".gz"

            logging.info(f"开始备份MySQL数据库: {db_name}")

            # 构建mysqldump命令
            cmd = [
                "mysqldump",
                f"--host={db_config['host']}",
                f"--port={db_config['port']}",
                f"--user={db_config['user']}",
                f"--password={db_config['password']}"
            ]

            # 添加额外选项
            if db_config['options']:
                cmd.extend(db_config['options'].split())

            cmd.append(db_name)

            try:
                if self.config['compression'] == 'gzip':
                    with open(output_file, 'wb') as f:
                        dump_process = subprocess.Popen(cmd, stdout=subprocess.PIPE)
                        gzip_process = subprocess.Popen(['gzip'], stdin=dump_process.stdout, stdout=f)
                        dump_process.stdout.close()  # 允许dump_process在pipe关闭时收到SIGPIPE
                        gzip_process.communicate()

                        if dump_process.wait() != 0:
                            logging.error(f"备份MySQL数据库 {db_name} 失败")
                            if os.path.exists(output_file):
                                os.remove(output_file)
                            continue
                else:
                    with open(output_file, 'wb') as f:
                        result = subprocess.run(cmd, stdout=f)
                        if result.returncode != 0:
                            logging.error(f"备份MySQL数据库 {db_name} 失败")
                            if os.path.exists(output_file):
                                os.remove(output_file)
                            continue

                backup_size = os.path.getsize(output_file)
                backup_files.append({
                    'file': output_file,
                    'database': db_name,
                    'type': 'mysql',
                    'timestamp': timestamp,
                    'size': backup_size,
                    'size_human': self._human_size(backup_size)
                })
                logging.info(f"MySQL数据库 {db_name} 备份成功，大小: {self._human_size(backup_size)}")

            except Exception as e:
                logging.error(f"备份MySQL数据库 {db_name} 时发生错误: {e}")
                if os.path.exists(output_file):
                    os.remove(output_file)

        return backup_files

    def backup_postgresql(self):
        """备份PostgreSQL数据库"""
        if not self.config['postgresql']['enabled']:
            logging.info("PostgreSQL备份功能未启用")
            return []

        backup_dir = self._ensure_backup_dir("postgresql")
        db_config = self.config['postgresql']
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        databases = self._get_postgresql_databases()
        backup_files = []

        for db_name in databases:
            output_file = os.path.join(backup_dir, f"{db_name}_{timestamp}.sql")

            if self.config['compression'] == 'gzip':
                output_file += ".gz"

            logging.info(f"开始备份PostgreSQL数据库: {db_name}")

            # 设置环境变量
            env = os.environ.copy()
            env["PGPASSWORD"] = db_config['password']

            # 构建pg_dump命令
            cmd = [
                "pg_dump",
                f"-h{db_config['host']}",
                f"-p{db_config['port']}",
                f"-U{db_config['user']}"
            ]

            # 添加额外选项
            if db_config['options']:
                cmd.extend(db_config['options'].split())

            cmd.extend(["-d", db_name])

            try:
                if self.config['compression'] == 'gzip':
                    with open(output_file, 'wb') as f:
                        dump_process = subprocess.Popen(cmd, stdout=subprocess.PIPE, env=env)
                        gzip_process = subprocess.Popen(['gzip'], stdin=dump_process.stdout, stdout=f)
                        dump_process.stdout.close()  # 允许dump_process在pipe关闭时收到SIGPIPE
                        gzip_process.communicate()

                        if dump_process.wait() != 0:
                            logging.error(f"备份PostgreSQL数据库 {db_name} 失败")
                            if os.path.exists(output_file):
                                os.remove(output_file)
                            continue
                else:
                    with open(output_file, 'wb') as f:
                        result = subprocess.run(cmd, stdout=f, env=env)
                        if result.returncode != 0:
                            logging.error(f"备份PostgreSQL数据库 {db_name} 失败")
                            if os.path.exists(output_file):
                                os.remove(output_file)
                            continue

                backup_size = os.path.getsize(output_file)
                backup_files.append({
                    'file': output_file,
                    'database': db_name,
                    'type': 'postgresql',
                    'timestamp': timestamp,
                    'size': backup_size,
                    'size_human': self._human_size(backup_size)
                })
                logging.info(f"PostgreSQL数据库 {db_name} 备份成功，大小: {self._human_size(backup_size)}")

            except Exception as e:
                logging.error(f"备份PostgreSQL数据库 {db_name} 时发生错误: {e}")
                if os.path.exists(output_file):
                    os.remove(output_file)

        return backup_files

    def _human_size(self, size_bytes):
        """将字节大小转换为人类可读格式"""
        if size_bytes == 0:
            return "0B"

        size_names = ("B", "KB", "MB", "GB", "TB", "PB", "EB", "ZB", "YB")
        i = int(math.floor(math.log(size_bytes, 1024)))
        p = math.pow(1024, i)
        s = round(size_bytes / p, 2)

        return f"{s} {size_names[i]}"

    def cleanup_old_backups(self):
        """清理旧的备份文件"""
        backup_types = ["mysql", "postgresql"]
        deleted_files = []
        saved_space = 0

        for backup_type in backup_types:
            backup_dir = os.path.join(self.config['backup_dir'], backup_type)
            if not os.path.exists(backup_dir):
                continue

            logging.info(f"开始清理旧的{backup_type}备份文件")
            retention = self.config['retention']

            # 获取目录中的所有备份文件
            files = []
            for f in os.listdir(backup_dir):
                file_path = os.path.join(backup_dir, f)
                if os.path.isfile(file_path):
                    # 从文件名提取日期时间信息
                    try:
                        match = re.search(r'_(\d{8})_(\d{6})', f)
                        if match:
                            date_str = match.group(1)
                            time_str = match.group(2)
                            file_date = datetime.strptime(f"{date_str}_{time_str}", "%Y%m%d_%H%M%S")

                            files.append({
                                'path': file_path,
                                'date': file_date,
                                'size': os.path.getsize(file_path)
                            })
                    except Exception as e:
                        logging.warning(f"无法从文件名提取日期: {f}, 错误: {e}")

            # 只保留最近N天的所有备份
            cutoff_date = datetime.now() - timedelta(days=retention['days'])
            for file_info in files:
                if file_info['date'] < cutoff_date:
                    try:
                        os.remove(file_info['path'])
                        logging.info(f"删除旧备份: {file_info['path']}")
                        deleted_files.append(file_info['path'])
                        saved_space += file_info['size']
                    except OSError as e:
                        logging.error(f"删除备份文件失败: {file_info['path']}, 错误: {e}")

        if deleted_files:
            logging.info(f"清理完成，共删除 {len(deleted_files)} 个文件，节省 {self._human_size(saved_space)} 空间")
        else:
            logging.info("没有找到需要清理的旧备份文件")

        return len(deleted_files), saved_space

    def send_notification(self, subject, message):
        """发送通知邮件"""
        if not self.config['notification']['enabled']:
            logging.info("通知功能未启用")
            return False

        email_config = self.config['notification']['email']

        try:
            msg = MIMEMultipart()
            msg['From'] = email_config['from']
            msg['To'] = ', '.join(email_config['to'])
            msg['Subject'] = subject

            msg.attach(MIMEText(message, 'plain'))

            server = smtplib.SMTP(email_config['server'], email_config['port'])
            if email_config['use_tls']:
                server.starttls()

            if email_config['username'] and email_config['password']:
                server.login(email_config['username'], email_config['password'])

            server.send_message(msg)
            server.quit()

            logging.info(f"已发送通知邮件: {subject}")
            return True
        except Exception as e:
            logging.error(f"发送通知邮件失败: {e}")
            return False

    def run_backup(self):
        """执行备份操作"""
        start_time = datetime.now()
        logging.info(f"开始数据库备份，时间: {start_time}")

        all_backups = []
        total_size = 0

        # 备份MySQL
        mysql_backups = self.backup_mysql()
        all_backups.extend(mysql_backups)

        # 备份PostgreSQL
        pg_backups = self.backup_postgresql()
        all_backups.extend(pg_backups)

        # 清理旧备份
        deleted_count, saved_space = self.cleanup_old_backups()

        # 计算总备份大小
        for backup in all_backups:
            total_size += backup['size']

        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        # 生成报告
        report = f"""
数据库备份报告

备份开始时间: {start_time}
备份结束时间: {end_time}
总耗时: {duration:.2f} 秒

备份文件摘要:
- 总文件数: {len(all_backups)}
- 总大小: {self._human_size(total_size)}

MySQL备份: {len(mysql_backups)} 个数据库
PostgreSQL备份: {len(pg_backups)} 个数据库

清理旧备份:
- 删除文件数: {deleted_count}
- 释放空间: {self._human_size(saved_space)}
"""

        # 添加备份文件详情
        if all_backups:
            report += "\n备份文件详情:\n"
            for backup in all_backups:
                report += f"- {backup['type']} - {backup['database']}: {backup['size_human']}\n"

        logging.info(f"备份完成，总共 {len(all_backups)} 个数据库，总大小 {self._human_size(total_size)}")

        # 发送通知
        if all_backups or deleted_count > 0:
            self.send_notification("数据库备份报告", report)

        return all_backups

def main():
    parser = argparse.ArgumentParser(description='数据库备份工具')
    parser.add_argument('-c', '--config', help='配置文件路径')
    args = parser.parse_args()

    try:
        import math
        import re
        backup = DatabaseBackup(args.config)
        backup.run_backup()
    except Exception as e:
        logging.error(f"备份过程中发生错误: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

## 综合实战案例

### 案例1：Web服务器运维自动化套件

这是一个综合性的Web服务器运维自动化套件，包括监控、日志分析、性能优化和安全检查功能。

```bash
#!/bin/bash
# web_server_automation.sh - Web服务器运维自动化套件

# 配置
CONFIG_FILE="/etc/web_automation/config.json"
LOG_FILE="/var/log/web_automation.log"
REPORT_DIR="/var/reports/web_automation"
EMAIL="admin@example.com"

# 确保目录存在
mkdir -p $(dirname $LOG_FILE)
mkdir -p $REPORT_DIR

# 日志函数
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a $LOG_FILE
}

# 发送邮件报告
send_report() {
    subject="$1"
    body="$2"
    attachment="$3"

    if [ -n "$attachment" ] && [ -f "$attachment" ]; then
        mutt -s "$subject" -a "$attachment" -- $EMAIL <<< "$body"
    else
        echo "$body" | mail -s "$subject" $EMAIL
    fi

    log "已发送报告: $subject"
}

# 检查系统负载
check_system_load() {
    log "检查系统负载..."

    # 获取系统负载
    load_avg=$(cat /proc/loadavg | awk '{print $1" "$2" "$3}')
    cpu_count=$(nproc)
    load_1min=$(echo $load_avg | awk '{print $1}')

    # 检查是否过载
    bc_result=$(echo "$load_1min > $cpu_count * 0.7" | bc -l)

    if [ "$bc_result" -eq 1 ]; then
        log "警告: 系统负载较高 ($load_avg)"
        return 1
    else
        log "系统负载正常 ($load_avg)"
        return 0
    fi
}

# 分析Nginx访问日志
analyze_nginx_logs() {
    log "分析Nginx访问日志..."

    nginx_log="/var/log/nginx/access.log"

    if [ ! -f "$nginx_log" ]; then
        log "错误: Nginx日志文件不存在"
        return 1
    fi

    report_file="$REPORT_DIR/nginx_analysis_$(date +%Y%m%d).txt"

    {
        echo "==== Nginx访问日志分析报告 $(date) ===="
        echo ""

        echo "== 访问量最高的IP地址(前10) =="
        awk '{print $1}' $nginx_log | sort | uniq -c | sort -nr | head -10
        echo ""

        echo "== 访问量最高的页面(前10) =="
        awk '{print $7}' $nginx_log | sort | uniq -c | sort -nr | head -10
        echo ""

        echo "== 404错误页面(前10) =="
        grep " 404 " $nginx_log | awk '{print $7}' | sort | uniq -c | sort -nr | head -10
        echo ""

        echo "== 500错误页面(前10) =="
        grep " 500 " $nginx_log | awk '{print $7}' | sort | uniq -c | sort -nr | head -10
        echo ""

        echo "== 请求方法统计 =="
        awk '{print $6}' $nginx_log | tr -d \" | sort | uniq -c | sort -nr
        echo ""

        echo "== 每小时请求数 =="
        awk '{print substr($4, 2, 2)}' $nginx_log | sort | uniq -c
        echo ""

        echo "== 状态码分布 =="
        awk '{print $9}' $nginx_log | sort | uniq -c | sort -nr

    } > $report_file

    log "Nginx日志分析报告已保存: $report_file"

    # 发送邮件报告
    send_report "Nginx日志分析报告" "请查看附件了解详细信息" $report_file

    return 0
}

# 检查SSL证书过期时间
check_ssl_certificates() {
    log "检查SSL证书过期情况..."

    report_file="$REPORT_DIR/ssl_check_$(date +%Y%m%d).txt"

    # 从配置文件获取域名列表
    domains=("example.com" "api.example.com" "www.example.com")

    {
        echo "==== SSL证书检查报告 $(date) ===="
        echo ""

        for domain in "${domains[@]}"; do
            echo "检查域名: $domain"
            expiry_date=$(echo | openssl s_client -servername $domain -connect $domain:443 2>/dev/null | openssl x509 -noout -enddate 2>/dev/null | cut -d= -f2)

            if [ -n "$expiry_date" ]; then
                expiry_epoch=$(date -d "$expiry_date" +%s)
                current_epoch=$(date +%s)
                seconds_diff=$((expiry_epoch - current_epoch))
                days_diff=$((seconds_diff / 86400))

                echo "  证书过期时间: $expiry_date"
                echo "  剩余天数: $days_diff"

                if [ $days_diff -lt 30 ]; then
                    echo "  !!! 警告: 证书将在30天内过期 !!!"
                fi
            else
                echo "  无法获取证书信息"
            fi
            echo ""
        done

    } > $report_file

    log "SSL证书检查报告已保存: $report_file"

    # 发送邮件报告
    send_report "SSL证书检查报告" "请查看附件了解详细信息" $report_file

    return 0
}

# 优化Nginx配置
optimize_nginx_config() {
    log "优化Nginx配置..."

    # 备份当前配置
    nginx_conf="/etc/nginx/nginx.conf"
    backup_file="/etc/nginx/nginx.conf.$(date +%Y%m%d%H%M%S)"

    if [ ! -f "$nginx_conf" ]; then
        log "错误: Nginx配置文件不存在"
        return 1
    fi

    cp $nginx_conf $backup_file
    log "已备份当前配置: $backup_file"

    # 获取系统信息
    cpu_cores=$(nproc)
    total_mem=$(free -m | grep Mem | awk '{print $2}')

    # 计算优化值
    worker_processes=$cpu_cores
    worker_connections=$((total_mem / 100))
    if [ $worker_connections -lt 1024 ]; then
        worker_connections=1024
    fi

    # 更新配置
    sed -i "s/worker_processes [0-9]*;/worker_processes $worker_processes;/" $nginx_conf
    sed -i "s/worker_connections [0-9]*;/worker_connections $worker_connections;/" $nginx_conf

    # 添加缓存和Gzip配置
    if ! grep -q "open_file_cache" $nginx_conf; then
        sed -i "/http {/a \\    open_file_cache max=1000 inactive=20s;" $nginx_conf
        sed -i "/open_file_cache max=1000 inactive=20s;/a \\    open_file_cache_valid 30s;" $nginx_conf
        sed -i "/open_file_cache_valid 30s;/a \\    open_file_cache_min_uses 2;" $nginx_conf
        sed -i "/open_file_cache_min_uses 2;/a \\    open_file_cache_errors on;" $nginx_conf
    fi

    if ! grep -q "gzip on" $nginx_conf; then
        sed -i "/http {/a \\    gzip on;" $nginx_conf
        sed -i "/gzip on;/a \\    gzip_comp_level 5;" $nginx_conf
        sed -i "/gzip_comp_level 5;/a \\    gzip_min_length 256;" $nginx_conf
        sed -i "/gzip_min_length 256;/a \\    gzip_types text/plain text/css application/javascript application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;" $nginx_conf
    fi

    # 测试配置
    nginx -t
    if [ $? -eq 0 ]; then
        systemctl reload nginx
        log "Nginx配置已优化并重新加载"
    else
        log "错误: Nginx配置测试失败，恢复备份"
        cp $backup_file $nginx_conf
        return 1
    fi

    return 0
}

# 安全检查
security_check() {
    log "执行安全检查..."

    report_file="$REPORT_DIR/security_check_$(date +%Y%m%d).txt"

    {
        echo "==== 安全检查报告 $(date) ===="
        echo ""

        echo "== 开放端口 =="
        netstat -tulpn | grep LISTEN
        echo ""

        echo "== 最近登录尝试 =="
        last | head -20
        echo ""

        echo "== 失败的登录尝试 =="
        grep "Failed password" /var/log/auth.log | tail -20
        echo ""

        echo "== 可疑进程 =="
        ps aux | awk '$3 > 50.0 || $4 > 50.0 {print}'
        echo ""

        echo "== Nginx安全配置检查 =="
        echo "检查HTTP头安全选项..."
        if grep -q "add_header X-Frame-Options" /etc/nginx/nginx.conf; then
            echo "X-Frame-Options 已配置"
        else
            echo "警告: 缺少 X-Frame-Options 配置"
        fi

        if grep -q "add_header X-Content-Type-Options" /etc/nginx/nginx.conf; then
            echo "X-Content-Type-Options 已配置"
        else
            echo "警告: 缺少 X-Content-Type-Options 配置"
        fi

        if grep -q "add_header X-XSS-Protection" /etc/nginx/nginx.conf; then
            echo "X-XSS-Protection 已配置"
        else
            echo "警告: 缺少 X-XSS-Protection 配置"
        fi
        echo ""

        echo "== 系统更新状态 =="
        apt update &>/dev/null  # 更新包列表
        apt list --upgradable 2>/dev/null | grep -v "正在列出" | grep -v "Listing"
        echo ""

    } > $report_file

    log "安全检查报告已保存: $report_file"

    # 发送邮件报告
    send_report "Web服务器安全检查报告" "请查看附件了解详细信息" $report_file

    return 0
}

# 备份网站数据
backup_website_data() {
    log "备份网站数据..."

    # 备份目录
    backup_dir="$REPORT_DIR/backups"
    mkdir -p $backup_dir

    timestamp=$(date +%Y%m%d%H%M%S)
    backup_file="$backup_dir/website_backup_$timestamp.tar.gz"

    # 要备份的网站目录
    web_dir="/var/www/html"

    if [ ! -d "$web_dir" ]; then
        log "错误: 网站目录不存在"
        return 1
    fi

    # 创建备份
    tar -czf $backup_file $web_dir
    if [ $? -eq 0 ]; then
        log "网站数据备份成功: $backup_file"

        # 清理旧备份 (保留最近7个)
        find $backup_dir -name "website_backup_*.tar.gz" -type f -mtime +7 -delete
    else
        log "错误: 网站数据备份失败"
        return 1
    fi

    return 0
}

# 主函数
main() {
    log "开始Web服务器自动化套件..."

    # 检查系统负载
    check_system_load

    # 分析Nginx日志
    analyze_nginx_logs

    # 检查SSL证书
    check_ssl_certificates

    # 优化Nginx配置
    optimize_nginx_config

    # 执行安全检查
    security_check

    # 备份网站数据
    backup_website_data

    log "自动化任务完成"
}

# 执行主函数
main
```

### 案例2：全栈式服务器自动化Python工具

这是一个使用Python实现的全栈式服务器自动化工具，集成了监控、告警、自动修复和报告功能。该工具使用模块化的设计，可以根据需求扩展功能。

```python
#!/usr/bin/env python3
# server_automation.py - 全栈式服务器自动化Python工具

import os
import sys
import time
import psutil
import logging
import argparse
import datetime
import subprocess
import smtplib
import json
import socket
import shutil
import re
import requests
from pathlib import Path
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("server_automation.log"),
        logging.StreamHandler()
    ]
)

# 默认配置
DEFAULT_CONFIG = {
    "server": {
        "name": socket.gethostname(),
        "environment": "production"
    },
    "monitoring": {
        "enabled": True,
        "interval": 300,  # 5分钟检查一次
        "thresholds": {
            "cpu_percent": 80,
            "memory_percent": 80,
            "disk_percent": 85
        }
    },
    "services": [
        {
            "name": "nginx",
            "type": "systemd",
            "check_ports": [80, 443],
            "check_process": "nginx",
            "restart_command": "systemctl restart nginx",
            "config_test_command": "nginx -t",
            "log_file": "/var/log/nginx/error.log",
            "auto_restart": True
        },
        {
            "name": "mysql",
            "type": "systemd",
            "check_ports": [3306],
            "check_process": "mysqld",
            "restart_command": "systemctl restart mysql",
            "log_file": "/var/log/mysql/error.log",
            "auto_restart": True
        }
    ],
    "backup": {
        "enabled": True,
        "web_dirs": ["/var/www/html"],
        "databases": [
            {
                "type": "mysql",
                "name": "wordpress",
                "user": "backup_user",
                "password": "backup_password"
            }
        ],
        "backup_dir": "/var/backups/server",
        "retention_days": 7
    },
    "security": {
        "enabled": True,
        "check_ssh": True,
        "check_firewall": True,
        "check_updates": True,
        "check_failed_logins": True
    },
    "notifications": {
        "email": {
            "enabled": True,
            "server": "smtp.gmail.com",
            "port": 587,
            "use_tls": True,
            "username": "your_email@gmail.com",
            "password": "your_app_password",
            "from": "server_automation@example.com",
            "to": ["admin@example.com"]
        },
        "slack": {
            "enabled": False,
            "webhook_url": ""
        }
    },
    "reports": {
        "enabled": True,
        "daily": True,
        "weekly": True,
        "monthly": True,
        "report_dir": "/var/reports/server"
    }
}

class ServerAutomation:
    def __init__(self, config_file=None):
        """初始化服务器自动化工具"""
        self.config = self._load_config(config_file)
        self.server_name = self.config["server"]["name"]
        self.environment = self.config["server"]["environment"]

        # 确保必要的目录存在
        if self.config["backup"]["enabled"]:
            os.makedirs(self.config["backup"]["backup_dir"], exist_ok=True)

        if self.config["reports"]["enabled"]:
            os.makedirs(self.config["reports"]["report_dir"], exist_ok=True)

        self.alert_history = {}  # 用于跟踪已发送的警报

    def _load_config(self, config_file):
        """加载配置文件"""
        config = DEFAULT_CONFIG.copy()

        if config_file and os.path.exists(config_file):
            try:
                with open(config_file, 'r') as f:
                    user_config = json.load(f)

                # 递归合并配置
                def merge_configs(base, override):
                    for key, value in override.items():
                        if isinstance(value, dict) and key in base and isinstance(base[key], dict):
                            merge_configs(base[key], value)
                        else:
                            base[key] = value

                merge_configs(config, user_config)
                logging.info(f"已从 {config_file} 加载配置")
            except Exception as e:
                logging.error(f"加载配置文件失败: {e}")
                logging.info("使用默认配置")
        else:
            logging.info("使用默认配置")

        return config

    def _send_email(self, subject, body, attachments=None):
        """发送电子邮件通知"""
        if not self.config["notifications"]["email"]["enabled"]:
            return False

        email_config = self.config["notifications"]["email"]

        try:
            msg = MIMEMultipart()
            msg['From'] = email_config["from"]
            msg['To'] = ", ".join(email_config["to"])
            msg['Subject'] = f"[{self.environment}] {self.server_name}: {subject}"

            msg.attach(MIMEText(body, 'plain'))

            # 添加附件
            if attachments:
                for file_path in attachments:
                    if os.path.isfile(file_path):
                        with open(file_path, "rb") as f:
                            part = MIMEApplication(f.read(), Name=os.path.basename(file_path))
                            part['Content-Disposition'] = f'attachment; filename="{os.path.basename(file_path)}"'
                            msg.attach(part)

            # 连接到SMTP服务器
            server = smtplib.SMTP(email_config["server"], email_config["port"])
            if email_config["use_tls"]:
                server.starttls()

            server.login(email_config["username"], email_config["password"])
            server.send_message(msg)
            server.quit()

            logging.info(f"已发送邮件: {subject}")
            return True
        except Exception as e:
            logging.error(f"发送邮件失败: {e}")
            return False

    def _send_slack(self, title, message):
        """发送Slack通知"""
        if not self.config["notifications"]["slack"]["enabled"]:
            return False

        slack_config = self.config["notifications"]["slack"]

        try:
            payload = {
                "text": f"*[{self.environment}] {self.server_name}: {title}*\n{message}"
            }

            response = requests.post(
                slack_config["webhook_url"],
                data=json.dumps(payload),
                headers={"Content-Type": "application/json"}
            )

            if response.status_code == 200:
                logging.info(f"已发送Slack通知: {title}")
                return True
            else:
                logging.error(f"发送Slack通知失败: {response.status_code}, {response.text}")
                return False
        except Exception as e:
            logging.error(f"发送Slack通知失败: {e}")
            return False

    def _send_notification(self, title, message, level="info", attachments=None):
        """发送通知（邮件和Slack）"""
        prefix = ""
        if level == "warning":
            prefix = "警告: "
        elif level == "error":
            prefix = "错误: "
        elif level == "critical":
            prefix = "严重: "

        # 发送邮件
        self._send_email(prefix + title, message, attachments)

        # 发送Slack
        self._send_slack(prefix + title, message)

    def _check_service_port(self, port):
        """检查端口是否开放"""
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(2)
            result = sock.connect_ex(('127.0.0.1', port))
            sock.close()
            return result == 0
        except:
            return False

    def _check_process_running(self, process_name):
        """检查进程是否运行"""
        try:
            output = subprocess.check_output(["pgrep", "-f", process_name]).decode().strip()
            return len(output) > 0
        except:
            return False

    def _execute_command(self, command):
        """执行命令并返回结果"""
        try:
            result = subprocess.run(command, shell=True, check=False, 
                                  stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                                  text=True)
            return {
                "success": result.returncode == 0,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "returncode": result.returncode
            }
        except Exception as e:
            return {
                "success": False,
                "stdout": "",
                "stderr": str(e),
                "returncode": -1
            }

    def _should_send_alert(self, alert_key, cooldown_minutes=30):
        """判断是否应该发送警报（避免频繁发送同一警报）"""
        now = datetime.datetime.now()

        if alert_key in self.alert_history:
            last_time = self.alert_history[alert_key]
            # 如果在冷却时间内，则不发送
            if (now - last_time).total_seconds() < (cooldown_minutes * 60):
                return False

        # 更新警报历史
        self.alert_history[alert_key] = now
        return True

    def monitor_system_resources(self):
        """监控系统资源（CPU、内存、磁盘）"""
        if not self.config["monitoring"]["enabled"]:
            return True

        logging.info("检查系统资源...")
        thresholds = self.config["monitoring"]["thresholds"]
        alerts = []

        # 检查CPU使用率
        cpu_percent = psutil.cpu_percent(interval=1)
        if cpu_percent > thresholds["cpu_percent"]:
            alert = f"CPU使用率过高: {cpu_percent}% (阈值: {thresholds['cpu_percent']}%)"
            if self._should_send_alert("high_cpu"):
                alerts.append(alert)
            logging.warning(alert)

        # 检查内存使用率
        memory = psutil.virtual_memory()
        if memory.percent > thresholds["memory_percent"]:
            alert = f"内存使用率过高: {memory.percent}% (阈值: {thresholds['memory_percent']}%)"
            if self._should_send_alert("high_memory"):
                alerts.append(alert)
            logging.warning(alert)

        # 检查磁盘使用率
        for partition in psutil.disk_partitions():
            try:
                usage = psutil.disk_usage(partition.mountpoint)
                if usage.percent > thresholds["disk_percent"]:
                    alert = f"磁盘使用率过高 ({partition.mountpoint}): {usage.percent}% (阈值: {thresholds['disk_percent']}%)"
                    if self._should_send_alert(f"high_disk_{partition.mountpoint}"):
                        alerts.append(alert)
                    logging.warning(alert)
            except:
                pass

        # 如果有警报，发送通知
        if alerts:
            message = "系统资源警报:\n\n" + "\n".join(alerts)
            self._send_notification("系统资源警报", message, "warning")
            return False

        return True

    def check_services(self):
        """检查服务状态并尝试修复问题"""
        services = self.config["services"]
        all_ok = True

        for service in services:
            service_name = service["name"]
            logging.info(f"检查服务: {service_name}")

            # 检查进程
            process_running = True
            if "check_process" in service:
                process_running = self._check_process_running(service["check_process"])

            # 检查端口
            ports_ok = True
            if "check_ports" in service:
                for port in service["check_ports"]:
                    if not self._check_service_port(port):
                        logging.warning(f"服务 {service_name} 的端口 {port} 未开放")
                        ports_ok = False

            # 如果进程或端口检查失败
            if not process_running or not ports_ok:
                logging.warning(f"服务 {service_name} 可能已停止或不正常")
                all_ok = False

                # 尝试重启服务
                if service.get("auto_restart", False):
                    logging.info(f"尝试重启服务: {service_name}")

                    # 如果有配置测试命令，先测试配置
                    if "config_test_command" in service:
                        test_result = self._execute_command(service["config_test_command"])
                        if not test_result["success"]:
                            logging.error(f"服务 {service_name} 配置测试失败: {test_result['stderr']}")
                            self._send_notification(
                                f"服务 {service_name} 配置错误",
                                f"服务 {service_name} 配置测试失败，无法自动重启:\n\n{test_result['stderr']}",
                                "error"
                            )
                            continue

                    # 执行重启命令
                    restart_result = self._execute_command(service["restart_command"])
                    if restart_result["success"]:
                        logging.info(f"服务 {service_name} 重启成功")
                        self._send_notification(
                            f"服务 {service_name} 已自动重启",
                            f"服务 {service_name} 被检测到异常并已成功重启。",
                            "warning"
                        )
                    else:
                        logging.error(f"服务 {service_name} 重启失败: {restart_result['stderr']}")
                        self._send_notification(
                            f"服务 {service_name} 重启失败",
                            f"服务 {service_name} 重启失败:\n\n{restart_result['stderr']}",
                            "error"
                        )
                else:
                    # 如果不自动重启，发送通知
                    self._send_notification(
                        f"服务 {service_name} 异常",
                        f"服务 {service_name} 可能已停止或不正常，需要手动检查。",
                        "warning"
                    )

        return all_ok

    def backup_data(self):
        """备份网站数据和数据库"""
        if not self.config["backup"]["enabled"]:
            return True

        backup_config = self.config["backup"]
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = backup_config["backup_dir"]
        backups_created = []

        # 备份网站目录
        if "web_dirs" in backup_config and backup_config["web_dirs"]:
            for web_dir in backup_config["web_dirs"]:
                if not os.path.exists(web_dir):
                    logging.warning(f"网站目录不存在: {web_dir}")
                    continue

                dir_name = os.path.basename(web_dir.rstrip('/'))
                backup_file = os.path.join(backup_dir, f"web_{dir_name}_{timestamp}.tar.gz")

                logging.info(f"备份网站目录: {web_dir}")
                try:
                    with tarfile.open(backup_file, "w:gz") as tar:
                        tar.add(web_dir, arcname=dir_name)

                    backups_created.append({
                        "type": "web",
                        "source": web_dir,
                        "file": backup_file,
                        "size": os.path.getsize(backup_file)
                    })

                    logging.info(f"网站目录备份完成: {backup_file}")
                except Exception as e:
                    logging.error(f"备份网站目录失败: {web_dir}, 错误: {e}")

        # 备份数据库
        if "databases" in backup_config and backup_config["databases"]:
            for db in backup_config["databases"]:
                db_type = db["type"]
                db_name = db["name"]

                if db_type == "mysql":
                    backup_file = os.path.join(backup_dir, f"mysql_{db_name}_{timestamp}.sql.gz")

                    logging.info(f"备份MySQL数据库: {db_name}")
                    try:
                        cmd = f"mysqldump -u {db['user']} -p'{db['password']}' {db_name} | gzip > {backup_file}"
                        result = subprocess.run(cmd, shell=True, check=True, stderr=subprocess.PIPE, text=True)

                        backups_created.append({
                            "type": "database",
                            "source": f"mysql:{db_name}",
                            "file": backup_file,
                            "size": os.path.getsize(backup_file)
                        })

                        logging.info(f"MySQL数据库备份完成: {backup_file}")
                    except Exception as e:
                        logging.error(f"备份MySQL数据库失败: {db_name}, 错误: {e}")

                elif db_type == "postgresql":
                    backup_file = os.path.join(backup_dir, f"pgsql_{db_name}_{timestamp}.sql.gz")

                    logging.info(f"备份PostgreSQL数据库: {db_name}")
                    try:
                        env = os.environ.copy()
                        env["PGPASSWORD"] = db["password"]

                        cmd = f"pg_dump -U {db['user']} {db_name} | gzip > {backup_file}"
                        result = subprocess.run(cmd, shell=True, check=True, stderr=subprocess.PIPE, text=True, env=env)

                        backups_created.append({
                            "type": "database",
                            "source": f"postgresql:{db_name}",
                            "file": backup_file,
                            "size": os.path.getsize(backup_file)
                        })

                        logging.info(f"PostgreSQL数据库备份完成: {backup_file}")
                    except Exception as e:
                        logging.error(f"备份PostgreSQL数据库失败: {db_name}, 错误: {e}")

        # 清理旧备份
        if "retention_days" in backup_config and backup_config["retention_days"] > 0:
            retention_days = backup_config["retention_days"]
            cutoff_time = time.time() - (retention_days * 86400)

            deleted_files = 0
            saved_space = 0

            for file in os.listdir(backup_dir):
                file_path = os.path.join(backup_dir, file)
                if os.path.isfile(file_path) and os.path.getmtime(file_path) < cutoff_time:
                    try:
                        file_size = os.path.getsize(file_path)
                        os.remove(file_path)
                        deleted_files += 1
                        saved_space += file_size
                        logging.info(f"已删除旧备份: {file_path}")
                    except Exception as e:
                        logging.error(f"删除旧备份失败: {file_path}, 错误: {e}")

            if deleted_files > 0:
                logging.info(f"已清理 {deleted_files} 个旧备份，释放空间 {self._format_size(saved_space)}")

        # 发送备份报告
        if backups_created:
            total_size = sum(backup["size"] for backup in backups_created)

            report = f"备份摘要:\n\n"
            report += f"创建时间: {datetime.datetime.now()}\n"
            report += f"备份总数: {len(backups_created)}\n"
            report += f"总大小: {self._format_size(total_size)}\n\n"
            report += "备份详情:\n"

            for backup in backups_created:
                report += f"- {backup['type']} - {backup['source']}: {self._format_size(backup['size'])}\n"

            self._send_notification(
                "备份完成",
                report,
                "info"
            )

            return True
        else:
            self._send_notification(
                "备份失败",
                "未创建任何备份，请检查日志获取详细信息。",
                "error"
            )

            return False

    def _format_size(self, size_bytes):
        """格式化字节大小为人类可读格式"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024 or unit == 'TB':
                return f"{size_bytes:.2f} {unit}"
            size_bytes /= 1024

    def security_check(self):
        """执行安全检查"""
        if not self.config["security"]["enabled"]:
            return True

        logging.info("执行安全检查...")
        security_config = self.config["security"]
        report_file = os.path.join(
            self.config["reports"]["report_dir"],
            f"security_check_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        )

        with open(report_file, 'w') as f:
            f.write(f"=== 服务器安全检查报告 ===\n")
            f.write(f"服务器: {self.server_name}\n")
            f.write(f"环境: {self.environment}\n")
            f.write(f"检查时间: {datetime.datetime.now()}\n\n")

            # 检查SSH配置
            if security_config.get("check_ssh", False):
                f.write("== SSH配置检查 ==\n")

                try:
                    with open('/etc/ssh/sshd_config', 'r') as ssh_file:
                        ssh_config = ssh_file.read()

                    # 检查常见的SSH安全配置
                    issues = []

                    if "PermitRootLogin yes" in ssh_config:
                        issues.append("允许root用户直接登录")

                    if "PasswordAuthentication yes" in ssh_config and "PubkeyAuthentication no" in ssh_config:
                        issues.append("只启用了密码认证，没有启用密钥认证")

                    f.write(f"检查结果: {'有问题' if issues else '正常'}\n")
                    if issues:
                        for issue in issues:
                            f.write(f"- {issue}\n")

                except Exception as e:
                    f.write(f"检查失败: {e}\n")

                f.write("\n")

            # 检查防火墙状态
            if security_config.get("check_firewall", False):
                f.write("== 防火墙状态检查 ==\n")

                try:
                    # 检查UFW (Ubuntu)
                    ufw_result = self._execute_command("ufw status")
                    if ufw_result["success"]:
                        f.write("UFW状态:\n")
                        f.write(ufw_result["stdout"])

                    # 检查firewalld (CentOS/RHEL)
                    firewalld_result = self._execute_command("firewall-cmd --state")
                    if firewalld_result["success"]:
                        f.write("\nFirewalld状态: ")
                        f.write(firewalld_result["stdout"])

                    # 检查iptables
                    iptables_result = self._execute_command("iptables -L")
                    if iptables_result["success"]:
                        f.write("\nIptables规则:\n")
                        f.write(iptables_result["stdout"])

                except Exception as e:
                    f.write(f"检查失败: {e}\n")

                f.write("\n")

            # 检查系统更新
            if security_config.get("check_updates", False):
                f.write("== 系统更新检查 ==\n")

                try:
                    # 检测操作系统类型
                    if os.path.exists("/etc/debian_version"):
                        # Debian/Ubuntu
                        update_result = self._execute_command("apt update > /dev/null 2>&1 && apt list --upgradable 2>/dev/null")
                        if update_result["success"]:
                            upgradable = [line for line in update_result["stdout"].split('\n') if line and not line.startswith('Listing...')]
                            f.write(f"可更新的软件包数量: {len(upgradable)}\n")
                            if upgradable:
                                f.write("软件包列表:\n")
                                for pkg in upgradable[:20]:  # 只显示前20个
                                    f.write(f"- {pkg}\n")
                                if len(upgradable) > 20:
                                    f.write(f"...以及其他 {len(upgradable) - 20} 个软件包\n")

                    elif os.path.exists("/etc/redhat-release"):
                        # CentOS/RHEL
                        update_result = self._execute_command("yum check-update -q")
                        if update_result["returncode"] == 100:  # yum检查到更新返回100
                            upgradable = [line for line in update_result["stdout"].split('\n') if line and not line.startswith('Loaded plugins:')]
                            f.write(f"可更新的软件包数量: {len(upgradable)}\n")
                            if upgradable:
                                f.write("软件包列表:\n")
                                for pkg in upgradable[:20]:  # 只显示前20个
                                    f.write(f"- {pkg}\n")
                                if len(upgradable) > 20:
                                    f.write(f"...以及其他 {len(upgradable) - 20} 个软件包\n")
                        else:
                            f.write("系统已是最新\n")

                except Exception as e:
                    f.write(f"检查失败: {e}\n")

                f.write("\n")

            # 检查失败的登录尝试
            if security_config.get("check_failed_logins", False):
                f.write("== 失败登录尝试检查 ==\n")

                try:
                    # 从auth.log检查失败登录
                    auth_log_files = ["/var/log/auth.log", "/var/log/secure"]
                    failed_logins = []

                    for log_file in auth_log_files:
                        if os.path.exists(log_file):
                            grep_result = self._execute_command(f"grep 'Failed password' {log_file} | tail -20")
                            if grep_result["success"] and grep_result["stdout"]:
                                failed_logins.extend(grep_result["stdout"].split('\n'))

                    if failed_logins:
                        f.write(f"最近 {len(failed_logins)} 次失败的登录尝试:\n")
                        for login in failed_logins:
                            if login:
                                f.write(f"- {login}\n")
                    else:
                        f.write("未发现失败的登录尝试\n")

                except Exception as e:
                    f.write(f"检查失败: {e}\n")

                f.write("\n")

            # 检查开放的网络端口
            f.write("== 开放端口检查 ==\n")
            try:
                netstat_result = self._execute_command("ss -tulpn")
                if netstat_result["success"]:
                    f.write("开放的网络端口:\n")
                    f.write(netstat_result["stdout"])

            except Exception as e:
                f.write(f"检查失败: {e}\n")

            f.write("\n")

        # 发送安全检查报告
        self._send_notification(
            "安全检查报告",
            "服务器安全检查完成，请查看附件获取详细报告。",
            "info",
            [report_file]
        )

        return True

    def generate_report(self):
        """生成服务器状态报告"""
        if not self.config["reports"]["enabled"]:
            return True

        logging.info("生成服务器状态报告...")

        report_dir = self.config["reports"]["report_dir"]
        report_file = os.path.join(report_dir, f"server_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")

        with open(report_file, 'w') as f:
            f.write(f"=== 服务器状态报告 ===\n")
            f.write(f"服务器: {self.server_name}\n")
            f.write(f"环境: {self.environment}\n")
            f.write(f"报告生成时间: {datetime.datetime.now()}\n\n")

            # 系统信息
            f.write("== 系统信息 ==\n")
            f.write(f"操作系统: {platform.system()} {platform.release()}\n")
            f.write(f"主机名: {socket.gethostname()}\n")
            f.write(f"内核版本: {platform.version()}\n")

            uptime_seconds = time.time() - psutil.boot_time()
            days, remainder = divmod(uptime_seconds, 86400)
            hours, remainder = divmod(remainder, 3600)
            minutes, seconds = divmod(remainder, 60)
            f.write(f"运行时间: {int(days)}天 {int(hours)}小时 {int(minutes)}分钟\n\n")

            # CPU信息
            f.write("== CPU信息 ==\n")
            f.write(f"物理CPU核心数: {psutil.cpu_count(logical=False)}\n")
            f.write(f"逻辑CPU核心数: {psutil.cpu_count()}\n")

            cpu_usage = psutil.cpu_percent(interval=1, percpu=True)
            f.write(f"总体CPU使用率: {psutil.cpu_percent()}%\n")
            f.write("各核心使用率:\n")
            for i, usage in enumerate(cpu_usage):
                f.write(f"- CPU {i}: {usage}%\n")
            f.write("\n")

            # 内存信息
            f.write("== 内存信息 ==\n")
            memory = psutil.virtual_memory()
            f.write(f"总内存: {self._format_size(memory.total)}\n")
            f.write(f"可用内存: {self._format_size(memory.available)}\n")
            f.write(f"已用内存: {self._format_size(memory.used)}\n")
            f.write(f"内存使用率: {memory.percent}%\n")

            swap = psutil.swap_memory()
            f.write(f"Swap总量: {self._format_size(swap.total)}\n")
            f.write(f"Swap使用: {self._format_size(swap.used)}\n")
            f.write(f"Swap使用率: {swap.percent}%\n\n")

            # 磁盘信息
            f.write("== 磁盘信息 ==\n")
            for partition in psutil.disk_partitions():
                try:
                    usage = psutil.disk_usage(partition.mountpoint)
                    f.write(f"设备: {partition.device}\n")
                    f.write(f"挂载点: {partition.mountpoint}\n")
                    f.write(f"文件系统: {partition.fstype}\n")
                    f.write(f"总容量: {self._format_size(usage.total)}\n")
                    f.write(f"已用空间: {self._format_size(usage.used)}\n")
                    f.write(f"可用空间: {self._format_size(usage.free)}\n")
                    f.write(f"使用率: {usage.percent}%\n\n")
                except:
                    # 某些挂载点可能无法获取磁盘使用情况
                    pass

            # 网络信息
            f.write("== 网络信息 ==\n")
            net_io = psutil.net_io_counters()
            f.write(f"总发送字节: {self._format_size(net_io.bytes_sent)}\n")
            f.write(f"总接收字节: {self._format_size(net_io.bytes_recv)}\n\n")

            # 网络接口信息
            for nic, addresses in psutil.net_if_addrs().items():
                f.write(f"接口: {nic}\n")
                for address in addresses:
                    if address.family == socket.AF_INET:
                        f.write(f"  IPv4地址: {address.address}\n")
                    elif address.family == socket.AF_INET6:
                        f.write(f"  IPv6地址: {address.address}\n")
            f.write("\n")

            # 服务状态
            f.write("== 服务状态 ==\n")
            for service in self.config["services"]:
                service_name = service["name"]
                process_running = True
                if "check_process" in service:
                    process_running = self._check_process_running(service["check_process"])

                ports_ok = True
                port_status = []
                if "check_ports" in service:
                    for port in service["check_ports"]:
                        port_open = self._check_service_port(port)
                        if not port_open:
                            ports_ok = False
                        port_status.append(f"端口 {port}: {'开放' if port_open else '关闭'}")

                status = "正常" if process_running and ports_ok else "异常"
                f.write(f"服务: {service_name} - 状态: {status}\n")
                if "check_process" in service:
                    f.write(f"  进程 ({service['check_process']}): {'运行中' if process_running else '未运行'}\n")
                if port_status:
                    for ps in port_status:
                        f.write(f"  {ps}\n")
                f.write("\n")

            # 最近登录信息
            f.write("== 最近登录信息 ==\n")
            last_result = self._execute_command("last -n 10")
            if last_result["success"]:
                f.write(last_result["stdout"])
            f.write("\n")

            # 运行进程TOP10
            f.write("== CPU占用TOP10进程 ==\n")
            top_cpu_result = self._execute_command("ps aux --sort=-%cpu | head -11")
            if top_cpu_result["success"]:
                f.write(top_cpu_result["stdout"])
            f.write("\n")

            f.write("== 内存占用TOP10进程 ==\n")
            top_mem_result = self._execute_command("ps aux --sort=-%mem | head -11")
            if top_mem_result["success"]:
                f.write(top_mem_result["stdout"])
            f.write("\n")

            # 服务器时间
            f.write("== 服务器时间 ==\n")
            time_result = self._execute_command("date")
            if time_result["success"]:
                f.write(f"当前时间: {time_result['stdout']}")

            timezone_result = self._execute_command("timedatectl")
            if timezone_result["success"]:
                f.write(f"时区信息:\n{timezone_result['stdout']}")
            f.write("\n")

        # 发送报告
        self._send_notification(
            "服务器状态报告",
            "服务器状态报告已生成，请查看附件获取详细报告。",
            "info",
            [report_file]
        )

        return True

    def run(self):
        """运行所有自动化任务"""
        logging.info("开始运行服务器自动化任务...")

        results = {
            "monitor": self.monitor_system_resources(),
            "services": self.check_services(),
            "backup": False,
            "security": False,
            "report": False
        }

        # 根据当前小时确定是否应该执行更多任务
        current_hour = datetime.datetime.now().hour
        current_day = datetime.datetime.now().day

        # 每天凌晨2点执行备份
        if current_hour == 2:
            results["backup"] = self.backup_data()

        # 每天凌晨3点执行安全检查
        if current_hour == 3:
            results["security"] = self.security_check()

        # 每天早上8点生成报告
        if current_hour == 8:
            results["report"] = self.generate_report()

        logging.info("服务器自动化任务完成")
        return results

def main():
    parser = argparse.ArgumentParser(description="服务器自动化工具")
    parser.add_argument("-c", "--config", help="配置文件路径")
    parser.add_argument("--monitor", action="store_true", help="仅执行监控任务")
    parser.add_argument("--services", action="store_true", help="仅检查服务状态")
    parser.add_argument("--backup", action="store_true", help="仅执行备份任务")
    parser.add_argument("--security", action="store_true", help="仅执行安全检查")
    parser.add_argument("--report", action="store_true", help="仅生成报告")

    args = parser.parse_args()

    try:
        automation = ServerAutomation(args.config)

        if args.monitor:
            automation.monitor_system_resources()
        elif args.services:
            automation.check_services()
        elif args.backup:
            automation.backup_data()
        elif args.security:
            automation.security_check()
        elif args.report:
            automation.generate_report()
        else:
            automation.run()

    except Exception as e:
        logging.error(f"运行服务器自动化工具时发生错误: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

实用脚本小工具
-------

### 工具1：批量文件重命名工具

这是一个简单但非常实用的Python脚本，用来批量重命名文件，支持多种模式和正则表达式。

```python
#!/usr/bin/env python3
# file_renamer.py - 批量文件重命名工具

import os
import re
import sys
import argparse
import logging
from datetime import datetime
from pathlib import Path

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def rename_files(directory, pattern, replacement, regex=False, dry_run=False, recursive=False):
    """
    批量重命名文件

    参数:
        directory - 要处理的目录
        pattern - 要替换的模式
        replacement - 替换后的文本
        regex - 是否使用正则表达式
        dry_run - 如果为True，只显示将要重命名的文件，但不实际重命名
        recursive - 是否递归处理子目录
    """
    directory = Path(directory)
    if not directory.exists() or not directory.is_dir():
        logging.error(f"目录不存在或不是目录: {directory}")
        return False

    count = 0
    error_count = 0

    # 遍历目录，收集文件
    files = []
    if recursive:
        for root, _, filenames in os.walk(directory):
            for filename in filenames:
                files.append(Path(root) / filename)
    else:
        files = [f for f in directory.iterdir() if f.is_file()]

    # 进行重命名
    for file_path in files:
        original_name = file_path.name

        if regex:
            try:
                # 使用正则表达式替换
                new_name = re.sub(pattern, replacement, original_name)
            except re.error as e:
                logging.error(f"正则表达式错误: {e}")
                error_count += 1
                continue
        else:
            # 使用简单字符串替换
            new_name = original_name.replace(pattern, replacement)

        if new_name != original_name:
            new_path = file_path.parent / new_name

            # 检查新文件名是否已存在
            if new_path.exists():
                logging.warning(f"文件已存在，无法重命名: {new_path}")
                error_count += 1
                continue

            try:
                if not dry_run:
                    file_path.rename(new_path)

                count += 1
                action = "会被重命名为" if dry_run else "已重命名为"
                logging.info(f"{file_path} {action} {new_path}")
            except Exception as e:
                logging.error(f"重命名文件失败 {file_path}: {e}")
                error_count += 1

    mode = "演习模式" if dry_run else "实际执行"
    logging.info(f"{mode}: 共处理 {count} 个文件，失败 {error_count} 个")

    return count > 0

def add_sequence(directory, prefix="", suffix="", start=1, padding=3, ext=None, dry_run=False, recursive=False):
    """
    为文件添加序列号

    参数:
        directory - 要处理的目录
        prefix - 文件名前缀
        suffix - 文件名后缀
        start - 起始序号
        padding - 序号补零长度
        ext - 只处理特定扩展名的文件，如 'jpg'
        dry_run - 如果为True，只显示将要重命名的文件，但不实际重命名
        recursive - 是否递归处理子目录
    """
    directory = Path(directory)
    if not directory.exists() or not directory.is_dir():
        logging.error(f"目录不存在或不是目录: {directory}")
        return False

    count = 0
    error_count = 0

    # 遍历目录，收集文件
    files = []
    if recursive:
        for root, _, filenames in os.walk(directory):
            for filename in filenames:
                file_path = Path(root) / filename
                if ext and file_path.suffix.lower() != f".{ext}":
                    continue
                files.append(file_path)
    else:
        files = [f for f in directory.iterdir() if f.is_file() and (not ext or f.suffix.lower() == f".{ext}")]

    # 排序文件列表（可选，根据需要取消注释）
    # files.sort()

    # 进行重命名
    seq = start
    for file_path in files:
        # 构建新的文件名
        sequence = str(seq).zfill(padding)
        new_name = f"{prefix}{sequence}{suffix}{file_path.suffix}"
        new_path = file_path.parent / new_name

        # 检查新文件名是否已存在
        if new_path.exists():
            logging.warning(f"文件已存在，无法重命名: {new_path}")
            error_count += 1
            continue

        try:
            if not dry_run:
                file_path.rename(new_path)

            count += 1
            action = "会被重命名为" if dry_run else "已重命名为"
            logging.info(f"{file_path} {action} {new_path}")
        except Exception as e:
            logging.error(f"重命名文件失败 {file_path}: {e}")
            error_count += 1

        seq += 1

    mode = "演习模式" if dry_run else "实际执行"
    logging.info(f"{mode}: 共处理 {count} 个文件，失败 {error_count} 个")

    return count > 0

def rename_by_date(directory, format_str="yyyyMMdd_HHmmss", use_created=False, use_modified=False, 
                  use_exif=False, prefix="", suffix="", ext=None, dry_run=False, recursive=False):
    """
    根据文件日期重命名文件

    参数:
        directory - 要处理的目录
        format_str - 日期格式，使用y(年)M(月)d(日)H(时)m(分)s(秒)作为占位符
        use_created - 使用文件创建时间
        use_modified - 使用文件修改时间
        use_exif - 使用EXIF中的拍摄时间（对图片文件）
        prefix - 文件名前缀
        suffix - 文件名后缀
        ext - 只处理特定扩展名的文件
        dry_run - 如果为True，只显示将要重命名的文件，但不实际重命名
        recursive - 是否递归处理子目录
    """
    directory = Path(directory)
    if not directory.exists() or not directory.is_dir():
        logging.error(f"目录不存在或不是目录: {directory}")
        return False

    # 尝试导入PIL库以读取EXIF数据
    has_pil = False
    if use_exif:
        try:
            from PIL import Image
            from PIL.ExifTags import TAGS
            has_pil = True
        except ImportError:
            logging.warning("无法导入PIL库，将无法使用EXIF数据。请安装pillow: pip install pillow")
            use_exif = False

    # 转换格式字符串为datetime格式
    dt_format = format_str
    dt_format = dt_format.replace("yyyy", "%Y")
    dt_format = dt_format.replace("yy", "%y")
    dt_format = dt_format.replace("MM", "%m")
    dt_format = dt_format.replace("dd", "%d")
    dt_format = dt_format.replace("HH", "%H")
    dt_format = dt_format.replace("mm", "%M")
    dt_format = dt_format.replace("ss", "%S")

    count = 0
    error_count = 0

    # 遍历目录，收集文件
    files = []
    if recursive:
        for root, _, filenames in os.walk(directory):
            for filename in filenames:
                file_path = Path(root) / filename
                if ext and file_path.suffix.lower() != f".{ext}":
                    continue
                files.append(file_path)
    else:
        files = [f for f in directory.iterdir() if f.is_file() and (not ext or f.suffix.lower() == f".{ext}")]

    # 进行重命名
    for file_path in files:
        file_date = None

        # 获取日期
        if use_exif and has_pil and file_path.suffix.lower() in ['.jpg', '.jpeg', '.tiff', '.tif']:
            try:
                image = Image.open(file_path)
                exif_data = image._getexif()
                if exif_data:
                    for tag_id, value in exif_data.items():
                        tag = TAGS.get(tag_id, tag_id)
                        if tag == 'DateTimeOriginal':
                            # EXIF日期格式: 'YYYY:MM:DD HH:MM:SS'
                            file_date = datetime.strptime(value, '%Y:%m:%d %H:%M:%S')
                            break
            except Exception as e:
                logging.warning(f"无法获取EXIF数据 {file_path}: {e}")

        if not file_date and use_created:
            try:
                # 获取文件创建时间
                file_date = datetime.fromtimestamp(file_path.stat().st_ctime)
            except Exception as e:
                logging.warning(f"无法获取文件创建时间 {file_path}: {e}")

        if not file_date and use_modified:
            try:
                # 获取文件修改时间
                file_date = datetime.fromtimestamp(file_path.stat().st_mtime)
            except Exception as e:
                logging.warning(f"无法获取文件修改时间 {file_path}: {e}")

        if not file_date:
            # 默认使用当前时间
            file_date = datetime.now()

        # 构建新的文件名
        date_str = file_date.strftime(dt_format)
        new_name = f"{prefix}{date_str}{suffix}{file_path.suffix}"
        new_path = file_path.parent / new_name

        # 检查新文件名是否已存在
        if new_path.exists():
            # 添加唯一标识符
            counter = 1
            while new_path.exists():
                counter_name = f"{prefix}{date_str}_{counter}{suffix}{file_path.suffix}"
                new_path = file_path.parent / counter_name
                counter += 1
            new_name = new_path.name

        try:
            if not dry_run:
                file_path.rename(new_path)

            count += 1
            action = "会被重命名为" if dry_run else "已重命名为"
            logging.info(f"{file_path} {action} {new_path}")
        except Exception as e:
            logging.error(f"重命名文件失败 {file_path}: {e}")
            error_count += 1

    mode = "演习模式" if dry_run else "实际执行"
    logging.info(f"{mode}: 共处理 {count} 个文件，失败 {error_count} 个")

    return count > 0

def main():
    parser = argparse.ArgumentParser(description="批量文件重命名工具")
    subparsers = parser.add_subparsers(dest="command", help="子命令")

    # 替换模式
    replace_parser = subparsers.add_parser("replace", help="替换文件名中的文本")
    replace_parser.add_argument("directory", help="要处理的目录")
    replace_parser.add_argument("pattern", help="要替换的模式")
    replace_parser.add_argument("replacement", help="替换后的文本")
    replace_parser.add_argument("-r", "--regex", action="store_true", help="使用正则表达式")
    replace_parser.add_argument("-d", "--dry-run", action="store_true", help="演习模式，不实际重命名")
    replace_parser.add_argument("--recursive", action="store_true", help="递归处理子目录")

    # 序列号模式
    sequence_parser = subparsers.add_parser("sequence", help="添加序列号")
    sequence_parser.add_argument("directory", help="要处理的目录")
    sequence_parser.add_argument("-p", "--prefix", default="", help="文件名前缀")
    sequence_parser.add_argument("-s", "--suffix", default="", help="文件名后缀")
    sequence_parser.add_argument("--start", type=int, default=1, help="起始序号")
    sequence_parser.add_argument("--padding", type=int, default=3, help="序号补零长度")
    sequence_parser.add_argument("-e", "--ext", help="只处理特定扩展名的文件")
    sequence_parser.add_argument("-d", "--dry-run", action="store_true", help="演习模式，不实际重命名")
    sequence_parser.add_argument("--recursive", action="store_true", help="递归处理子目录")

    # 日期模式
    date_parser = subparsers.add_parser("date", help="根据文件日期重命名")
    date_parser.add_argument("directory", help="要处理的目录")
    date_parser.add_argument("-f", "--format", default="yyyyMMdd_HHmmss", help="日期格式")
    date_parser.add_argument("-c", "--created", action="store_true", help="使用文件创建时间")
    date_parser.add_argument("-m", "--modified", action="store_true", help="使用文件修改时间")
    date_parser.add_argument("--exif", action="store_true", help="使用EXIF中的拍摄时间（对图片文件）")
    date_parser.add_argument("-p", "--prefix", default="", help="文件名前缀")
    date_parser.add_argument("-s", "--suffix", default="", help="文件名后缀")
    date_parser.add_argument("-e", "--ext", help="只处理特定扩展名的文件")
    date_parser.add_argument("-d", "--dry-run", action="store_true", help="演习模式，不实际重命名")
    date_parser.add_argument("--recursive", action="store_true", help="递归处理子目录")

    args = parser.parse_args()

    if args.command == "replace":
        rename_files(args.directory, args.pattern, args.replacement, args.regex, args.dry_run, args.recursive)
    elif args.command == "sequence":
        add_sequence(args.directory, args.prefix, args.suffix, args.start, args.padding, args.ext, args.dry_run, args.recursive)
    elif args.command == "date":
        rename_by_date(args.directory, args.format, args.created, args.modified, args.exif, args.prefix, args.suffix, args.ext, args.dry_run, args.recursive)
    else:
        parser.print_help()
        sys.exit(1)

if __name__ == "__main__":
    main()
```

### 工具2: 日志分析器

这是一个用Bash编写的通用日志分析工具，可以提取各种日志文件中的有用信息。

```python
#!/bin/bash
# log_analyzer.sh - 通用日志分析工具

# 设置默认值
LOG_FILE=""
OUTPUT_DIR="./log_analysis"
DATE_FORMAT=""
LINES=50
SEARCH_TERM=""
SINCE=""
UNTIL=""
ERROR_ONLY=false
ACCESS_LOG=false
TIME_RANGE=""
REMOTE_HOST=""
FILTER_IP=""

# 帮助函数
show_help() {
    echo "用法: $0 [选项] -f <日志文件>"
    echo ""
    echo "选项:"
    echo "  -f, --file FILE         要分析的日志文件"
    echo "  -o, --output DIR        输出目录 (默认: ./log_analysis)"
    echo "  -d, --date-format FMT   日志的日期格式 (例如: '%Y-%m-%d %H:%M:%S')"
    echo "  -n, --lines N           显示的行数 (默认: 50)"
    echo "  -s, --search TERM       搜索指定词语"
    echo "  -S, --since DATETIME    仅显示指定时间之后的条目"
    echo "  -U, --until DATETIME    仅显示指定时间之前的条目"
    echo "  -e, --errors            仅分析错误 (ERROR, CRITICAL, FATAL 等)"
    echo "  -a, --access-log        将文件作为网络服务器访问日志处理"
    echo "  -t, --time-range RANGE  分析特定时间范围内的记录 (格式: HH:MM-HH:MM)"
    echo "  -r, --remote-host HOST  分析来自特定远程主机的日志"
    echo "  -i, --filter-ip IP      过滤特定IP地址"
    echo "  -h, --help              显示此帮助信息"
    echo ""
    echo "示例:"
    echo "  $0 -f /var/log/messages -o ./reports -e"
    echo "  $0 -f /var/log/apache2/access.log -a -i 192.168.1.10"
    exit 1
}

# 解析参数
while [[ $# -gt 0 ]]; do
    case $1 in
        -f|--file)
            LOG_FILE="$2"
            shift 2
            ;;
        -o|--output)
            OUTPUT_DIR="$2"
            shift 2
            ;;
        -d|--date-format)
            DATE_FORMAT="$2"
            shift 2
            ;;
        -n|--lines)
            LINES="$2"
            shift 2
            ;;
        -s|--search)
            SEARCH_TERM="$2"
            shift 2
            ;;
        -S|--since)
            SINCE="$2"
            shift 2
            ;;
        -U|--until)
            UNTIL="$2"
            shift 2
            ;;
        -e|--errors)
            ERROR_ONLY=true
            shift
            ;;
        -a|--access-log)
            ACCESS_LOG=true
            shift
            ;;
        -t|--time-range)
            TIME_RANGE="$2"
            shift 2
            ;;
        -r|--remote-host)
            REMOTE_HOST="$2"
            shift 2
            ;;
        -i|--filter-ip)
            FILTER_IP="$2"
            shift 2
            ;;
        -h|--help)
            show_help
            ;;
        *)
            echo "未知参数: $1"
            show_help
            ;;
    esac
done

# 检查必须的参数
if [ -z "$LOG_FILE" ]; then
    echo "错误: 必须指定日志文件 (-f 选项)"
    show_help
fi

if [ ! -f "$LOG_FILE" ]; then
    echo "错误: 日志文件不存在: $LOG_FILE"
    exit 1
fi

# 创建输出目录
mkdir -p "$OUTPUT_DIR"
if [ ! -d "$OUTPUT_DIR" ]; then
    echo "错误: 无法创建输出目录: $OUTPUT_DIR"
    exit 1
fi

# 设置输出文件
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BASE_NAME=$(basename "$LOG_FILE")
REPORT_FILE="$OUTPUT_DIR/log_analysis_${BASE_NAME}_${TIMESTAMP}.txt"

# 开始分析
echo "=== 日志分析报告 ===" > "$REPORT_FILE"
echo "日志文件: $LOG_FILE" >> "$REPORT_FILE"
echo "分析时间: $(date)" >> "$REPORT_FILE"
echo "" >> "$REPORT_FILE"

# 基本统计信息
echo "== 基本统计 ==" >> "$REPORT_FILE"
echo "总行数: $(wc -l < "$LOG_FILE")" >> "$REPORT_FILE"
echo "文件大小: $(du -h "$LOG_FILE" | cut -f1)" >> "$REPORT_FILE"
echo "" >> "$REPORT_FILE"

# 根据日志类型进行特定分析
if [ "$ACCESS_LOG" = true ]; then
    # 网络服务器访问日志分析

    echo "== 访问日志分析 ==" >> "$REPORT_FILE"

    # HTTP状态码统计
    echo "HTTP状态码分布:" >> "$REPORT_FILE"
    awk '{print $9}' "$LOG_FILE" | sort | uniq -c | sort -nr >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"

    # 访问量最高的IP
    echo "访问量最高的IP地址 (前10):" >> "$REPORT_FILE"
    awk '{print $1}' "$LOG_FILE" | sort | uniq -c | sort -nr | head -10 >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"

    # 访问量最高的页面
    echo "访问量最高的URL (前10):" >> "$REPORT_FILE"
    awk '{print $7}' "$LOG_FILE" | sort | uniq -c | sort -nr | head -10 >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"

    # 请求方法统计
    echo "HTTP请求方法统计:" >> "$REPORT_FILE"
    awk '{print $6}' "$LOG_FILE" | tr -d '"' | sort | uniq -c | sort -nr >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"

    # 每小时请求数
    echo "每小时请求数:" >> "$REPORT_FILE"
    awk '{print substr($4, 2, 2)}' "$LOG_FILE" | sort | uniq -c >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"

    # 产生404错误的URL
    echo "产生404错误的URL (前20):" >> "$REPORT_FILE"
    grep " 404 " "$LOG_FILE" | awk '{print $7}' | sort | uniq -c | sort -nr | head -20 >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"

    # 产生500错误的URL
    echo "产生500错误的URL:" >> "$REPORT_FILE"
    grep " 500 " "$LOG_FILE" | awk '{print $7}' | sort | uniq -c | sort -nr >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"

    # 用户代理统计
    echo "用户代理统计 (前10):" >> "$REPORT_FILE"
    awk -F'"' '{print $6}' "$LOG_FILE" | sort | uniq -c | sort -nr | head -10 >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"

    # 如果指定了IP过滤
    if [ ! -z "$FILTER_IP" ]; then
        echo "指定IP ($FILTER_IP) 的访问记录:" >> "$REPORT_FILE"
        grep "^$FILTER_IP " "$LOG_FILE" | tail -n "$LINES" >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"
    fi

    # 可能的攻击尝试
    echo "可能的攻击尝试 (SQL注入, XSS等):" >> "$REPORT_FILE"
    grep -i -E "select|union|script|eval|\.\./|\<\%" "$LOG_FILE" | tail -n 50 >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"

else
    # 普通日志文件分析

    # 错误统计
    if [ "$ERROR_ONLY" = true ]; then
        echo "== 错误日志分析 ==" >> "$REPORT_FILE"
        grep -i -E "error|warning|critical|fatal|fail|exception" "$LOG_FILE" > /tmp/error_logs_$$

        echo "错误总数: $(wc -l < /tmp/error_logs_$$)" >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"

        echo "错误类型分布:" >> "$REPORT_FILE"
        grep -o -i -E "error|warning|critical|fatal|fail|exception" /tmp/error_logs_$$ | sort | uniq -c | sort -nr >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"

        echo "最近的错误 (最后 $LINES 行):" >> "$REPORT_FILE"
        tail -n "$LINES" /tmp/error_logs_$$ >> "$REPORT_FILE"

        rm /tmp/error_logs_$$
    else
        # 日志级别分布
        echo "== 日志级别分布 ==" >> "$REPORT_FILE"
        grep -o -i -E "debug|info|notice|warning|error|critical|alert|emergency" "$LOG_FILE" | sort | uniq -c | sort -nr >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"

        # 搜索特定词语
        if [ ! -z "$SEARCH_TERM" ]; then
            echo "== 搜索结果: \"$SEARCH_TERM\" ==" >> "$REPORT_FILE"
            grep -i "$SEARCH_TERM" "$LOG_FILE" | tail -n "$LINES" >> "$REPORT_FILE"
            echo "" >> "$REPORT_FILE"
        fi

        # 高频消息
        echo "== 高频消息 (前20条) ==" >> "$REPORT_FILE"
        # 去除时间戳和主机名，提取消息主体
        cat "$LOG_FILE" | sed -E 's/^([A-Za-z]+ [0-9]+ [0-9:]+) ([^ ]+) ([^:]+): (.*)$/\4/' | sort | uniq -c | sort -nr | head -20 >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"

        # 日志样本
        echo "== 日志样本 (最后 $LINES 行) ==" >> "$REPORT_FILE"
        tail -n "$LINES" "$LOG_FILE" >> "$REPORT_FILE"
    fi
fi

# 如果有指定时间范围
if [ ! -z "$TIME_RANGE" ]; then
    START_TIME=$(echo $TIME_RANGE | cut -d'-' -f1)
    END_TIME=$(echo $TIME_RANGE | cut -d'-' -f2)

    echo "== 时间范围分析 ($STAR


T_TIME 到 $END_TIME) ==" >> "$REPORT_FILE"
    # 提取时间并过滤
    grep -E "($START_TIME|$START_TIME:[0-9]+|$END_TIME|$END_TIME:[0-9]+)" "$LOG_FILE" | tail -n "$LINES" >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"
fi

echo "分析完成，报告已保存到: $REPORT_FILE"
```

### 工具3: 一键部署LAMP环境脚本

这是一个用Bash编写的一键部署LAMP(Linux, Apache, MySQL, PHP)环境的脚本，适用于Debian/Ubuntu和CentOS/RHEL系统。

```python
#!/bin/bash
# lamp_setup.sh - 一键部署LAMP环境脚本

# 设置ANSI颜色代码
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# 检查是否以root用户运行
if [ "$EUID" -ne 0 ]; then
  echo -e "${RED}错误: 请使用root权限运行此脚本${NC}"
  exit 1
fi

# 检测Linux发行版
if [ -f /etc/os-release ]; then
    . /etc/os-release
    OS=$NAME
    VER=$VERSION_ID
elif type lsb_release >/dev/null 2>&1; then
    OS=$(lsb_release -si)
    VER=$(lsb_release -sr)
else
    OS=$(uname -s)
    VER=$(uname -r)
fi

echo -e "${BLUE}===== LAMP环境自动部署脚本 =====${NC}"
echo -e "${BLUE}检测到操作系统: $OS $VER${NC}"

# 询问配置选项
read -p "请输入MySQL根密码 [默认: random]: " MYSQL_ROOT_PASS
if [ -z "$MYSQL_ROOT_PASS" ]; then
    MYSQL_ROOT_PASS=$(tr -dc 'A-Za-z0-9!@#$%^&*()' < /dev/urandom | head -c 16)
    echo "生成随机MySQL根密码: $MYSQL_ROOT_PASS"
fi

read -p "请输入Web根目录 [默认: /var/www/html]: " WEB_ROOT
WEB_ROOT=${WEB_ROOT:-/var/www/html}

read -p "请输入PHP版本 (7.4/8.0/8.1/8.2) [默认: 8.1]: " PHP_VERSION
PHP_VERSION=${PHP_VERSION:-8.1}

read -p "是否安装phpMyAdmin? (y/n) [默认: y]: " INSTALL_PHPMYADMIN
INSTALL_PHPMYADMIN=${INSTALL_PHPMYADMIN:-y}

read -p "是否配置基本安全设置? (y/n) [默认: y]: " CONFIGURE_SECURITY
CONFIGURE_SECURITY=${CONFIGURE_SECURITY:-y}

echo -e "${YELLOW}将安装以下组件:${NC}"
echo -e " - Apache Web服务器"
echo -e " - MySQL/MariaDB数据库服务器"
echo -e " - PHP $PHP_VERSION"
if [ "$INSTALL_PHPMYADMIN" = "y" ] || [ "$INSTALL_PHPMYADMIN" = "Y" ]; then
    echo -e " - phpMyAdmin"
fi
if [ "$CONFIGURE_SECURITY" = "y" ] || [ "$CONFIGURE_SECURITY" = "Y" ]; then
    echo -e " - 基本安全配置"
fi
echo -e " - Web根目录: $WEB_ROOT"

read -p "确认安装? (y/n) [默认: y]: " CONFIRM
CONFIRM=${CONFIRM:-y}

if [ "$CONFIRM" != "y" ] && [ "$CONFIRM" != "Y" ]; then
    echo -e "${YELLOW}安装已取消${NC}"
    exit 0
fi

# 创建日志文件
LOG_FILE="/tmp/lamp_install_$(date +%Y%m%d_%H%M%S).log"
echo -e "${BLUE}安装日志将保存在: $LOG_FILE${NC}"

# 系统更新函数
update_system() {
    echo -e "${BLUE}=== 更新系统 ===${NC}"
    
    if [[ "$OS" == *"Ubuntu"* ]] || [[ "$OS" == *"Debian"* ]]; then
        apt update -y >> $LOG_FILE 2>&1
        apt upgrade -y >> $LOG_FILE 2>&1
    elif [[ "$OS" == *"CentOS"* ]] || [[ "$OS" == *"Red Hat"* ]]; then
        yum update -y >> $LOG_FILE 2>&1
    else
        echo -e "${RED}不支持的操作系统: $OS${NC}"
        exit 1
    fi
    
    echo -e "${GREEN}系统更新完成${NC}"
}

# 安装Apache函数
install_apache() {
    echo -e "${BLUE}=== 安装Apache服务器 ===${NC}"
    
    if [[ "$OS" == *"Ubuntu"* ]] || [[ "$OS" == *"Debian"* ]]; then
        apt install -y apache2 >> $LOG_FILE 2>&1
        systemctl enable apache2 >> $LOG_FILE 2>&1
        systemctl start apache2 >> $LOG_FILE 2>&1
    elif [[ "$OS" == *"CentOS"* ]] || [[ "$OS" == *"Red Hat"* ]]; then
        yum install -y httpd >> $LOG_FILE 2>&1
        systemctl enable httpd >> $LOG_FILE 2>&1
        systemctl start httpd >> $LOG_FILE 2>&1
        
        # 配置防火墙
        if command -v firewall-cmd &> /dev/null; then
            firewall-cmd --permanent --add-service=http >> $LOG_FILE 2>&1
            firewall-cmd --permanent --add-service=https >> $LOG_FILE 2>&1
            firewall-cmd --reload >> $LOG_FILE 2>&1
        fi
    fi
    
    # 检查Apache是否成功安装和运行
    if pgrep -x "apache2" > /dev/null || pgrep -x "httpd" > /dev/null; then
        echo -e "${GREEN}Apache服务器安装并运行成功${NC}"
    else
        echo -e "${RED}Apache服务器安装或启动失败，请检查日志: $LOG_FILE${NC}"
        exit 1
    fi
    
    # 创建Web根目录(如果不是默认目录)
    if [ "$WEB_ROOT" != "/var/www/html" ]; then
        mkdir -p "$WEB_ROOT"
        
        if [[ "$OS" == *"Ubuntu"* ]] || [[ "$OS" == *"Debian"* ]]; then
            chown -R www-data:www-data "$WEB_ROOT"
            
            # 创建Apache虚拟主机配置
            cat > /etc/apache2/sites-available/000-default.conf << EOF
<VirtualHost *:80>
    ServerAdmin webmaster@localhost
    DocumentRoot $WEB_ROOT
    
    <Directory $WEB_ROOT>
        Options Indexes FollowSymLinks
        AllowOverride All
        Require all granted
    </Directory>
    
    ErrorLog \${APACHE_LOG_DIR}/error.log
    CustomLog \${APACHE_LOG_DIR}/access.log combined
</VirtualHost>
EOF
            # 启用新配置
            systemctl reload apache2 >> $LOG_FILE 2>&1
            
        elif [[ "$OS" == *"CentOS"* ]] || [[ "$OS" == *"Red Hat"* ]]; then
            chown -R apache:apache "$WEB_ROOT"
            
            # 创建Apache虚拟主机配置
            cat > /etc/httpd/conf.d/vhost.conf << EOF
<VirtualHost *:80>
    ServerAdmin webmaster@localhost
    DocumentRoot $WEB_ROOT
    
    <Directory $WEB_ROOT>
        Options Indexes FollowSymLinks
        AllowOverride All
        Require all granted
    </Directory>
    
    ErrorLog /var/log/httpd/error.log
    CustomLog /var/log/httpd/access.log combined
</VirtualHost>
EOF
            # 启用新配置
            systemctl reload httpd >> $LOG_FILE 2>&1
        fi
        
        echo -e "${GREEN}Web根目录已设置为: $WEB_ROOT${NC}"
    fi
}

# 安装MySQL/MariaDB函数
install_mysql() {
    echo -e "${BLUE}=== 安装MySQL/MariaDB数据库 ===${NC}"
    
    if [[ "$OS" == *"Ubuntu"* ]] || [[ "$OS" == *"Debian"* ]]; then
        # 使用非交互式方式安装MySQL并预设置root密码
        echo "mysql-server mysql-server/root_password password $MYSQL_ROOT_PASS" | debconf-set-selections
        echo "mysql-server mysql-server/root_password_again password $MYSQL_ROOT_PASS" | debconf-set-selections
        apt install -y mysql-server >> $LOG_FILE 2>&1
        systemctl enable mysql >> $LOG_FILE 2>&1
        systemctl start mysql >> $LOG_FILE 2>&1
    elif [[ "$OS" == *"CentOS"* ]] || [[ "$OS" == *"Red Hat"* ]]; then
        # CentOS默认使用MariaDB
        yum install -y mariadb-server >> $LOG_FILE 2>&1
        systemctl enable mariadb >> $LOG_FILE 2>&1
        systemctl start mariadb >> $LOG_FILE 2>&1
        
        # 设置root密码
        mysqladmin -u root password "$MYSQL_ROOT_PASS" >> $LOG_FILE 2>&1
        
        # 配置防火墙
        if command -v firewall-cmd &> /dev/null; then
            firewall-cmd --permanent --add-service=mysql >> $LOG_FILE 2>&1
            firewall-cmd --reload >> $LOG_FILE 2>&1
        fi
    fi
    
    # 检查MySQL/MariaDB是否成功安装和运行
    if pgrep -x "mysqld" > /dev/null || pgrep -x "mariadbd" > /dev/null; then
        echo -e "${GREEN}MySQL/MariaDB数据库安装并运行成功${NC}"
        
        # 创建一个简单的安全配置脚本
        cat > /tmp/secure_mysql.sql << EOF
UPDATE mysql.user SET Password=PASSWORD('$MYSQL_ROOT_PASS') WHERE User='root';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.db WHERE Db='test' OR Db='test\_%';
FLUSH PRIVILEGES;
EOF

        # 执行安全配置脚本
        if [[ "$OS" == *"Ubuntu"* ]] || [[ "$OS" == *"Debian"* ]]; then
            mysql -u root -p"$MYSQL_ROOT_PASS" < /tmp/secure_mysql.sql >> $LOG_FILE 2>&1
        elif [[ "$OS" == *"CentOS"* ]] || [[ "$OS" == *"Red Hat"* ]]; then
            mysql -u root -p"$MYSQL_ROOT_PASS" < /tmp/secure_mysql.sql >> $LOG_FILE 2>&1
        fi
        
        # 删除临时文件
        rm -f /tmp/secure_mysql.sql
        
        echo -e "${GREEN}MySQL/MariaDB安全配置已完成${NC}"
    else
        echo -e "${RED}MySQL/MariaDB安装或启动失败，请检查日志: $LOG_FILE${NC}"
        exit 1
    fi
}

# 安装PHP函数
install_php() {
    echo -e "${BLUE}=== 安装PHP $PHP_VERSION ===${NC}"
    
    if [[ "$OS" == *"Ubuntu"* ]] || [[ "$OS" == *"Debian"* ]]; then
        # 为较新版本的PHP添加源
        apt install -y software-properties-common apt-transport-https >> $LOG_FILE 2>&1
        
        # 不同OS版本可能需要不同的PPA
        if ! apt-cache show php$PHP_VERSION > /dev/null 2>&1; then
            add-apt-repository -y ppa:ondrej/php >> $LOG_FILE 2>&1
            apt update >> $LOG_FILE 2>&1
        fi
        
        # 安装PHP及常用扩展
        apt install -y php$PHP_VERSION php$PHP_VERSION-cli php$PHP_VERSION-common php$PHP_VERSION-mysql \
            php$PHP_VERSION-zip php$PHP_VERSION-gd php$PHP_VERSION-mbstring php$PHP_VERSION-curl \
            php$PHP_VERSION-xml php$PHP_VERSION-bcmath php$PHP_VERSION-json php$PHP_VERSION-intl \
            libapache2-mod-php$PHP_VERSION >> $LOG_FILE 2>&1
        
        # 重启Apache以加载PHP模块
        systemctl restart apache2 >> $LOG_FILE 2>&1
        
    elif [[ "$OS" == *"CentOS"* ]] || [[ "$OS" == *"Red Hat"* ]]; then
        # 根据CentOS版本安装EPEL和Remi源
        yum install -y epel-release >> $LOG_FILE 2>&1
        
        # 安装Remi软件源
        if [[ "$VER" == "7" ]]; then
            yum install -y https://rpms.remirepo.net/enterprise/remi-release-7.rpm >> $LOG_FILE 2>&1
        elif [[ "$VER" == "8" ]]; then
            yum install -y https://rpms.remirepo.net/enterprise/remi-release-8.rpm >> $LOG_FILE 2>&1
        elif [[ "$VER" == "9" ]]; then
            yum install -y https://rpms.remirepo.net/enterprise/remi-release-9.rpm >> $LOG_FILE 2>&1
        fi
        
        # 启用对应PHP版本的Remi源
        yum module reset php -y >> $LOG_FILE 2>&1
        yum module enable php:remi-$PHP_VERSION -y >> $LOG_FILE 2>&1
        
        # 安装PHP及常用扩展
        yum install -y php php-cli php-common php-mysqlnd php-zip php-gd php-mbstring \
            php-curl php-xml php-bcmath php-json php-intl >> $LOG_FILE 2>&1
        
        # 重启Apache以加载PHP模块
        systemctl restart httpd >> $LOG_FILE 2>&1
    fi
    
    # 检查PHP是否成功安装
    if command -v php &> /dev/null; then
        PHP_INSTALLED_VERSION=$(php -v | head -n 1 | cut -d' ' -f2 | cut -d'.' -f1,2)
        echo -e "${GREEN}PHP $PHP_INSTALLED_VERSION 安装成功${NC}"
        
        # 创建phpinfo文件
        cat > "$WEB_ROOT/phpinfo.php" << EOF
<?php
phpinfo();
?>
EOF

        # 设置适当的权限
        if [[ "$OS" == *"Ubuntu"* ]] || [[ "$OS" == *"Debian"* ]]; then
            chown www-data:www-data "$WEB_ROOT/phpinfo.php"
        elif [[ "$OS" == *"CentOS"* ]] || [[ "$OS" == *"Red Hat"* ]]; then
            chown apache:apache "$WEB_ROOT/phpinfo.php"
        fi
        
        echo -e "${GREEN}创建了phpinfo.php文件，可访问http://your-server-ip/phpinfo.php查看PHP信息${NC}"
    else
        echo -e "${RED}PHP安装失败，请检查日志: $LOG_FILE${NC}"
        exit 1
    fi
}

# 安装phpMyAdmin函数
install_phpmyadmin() {
    if [ "$INSTALL_PHPMYADMIN" != "y" ] && [ "$INSTALL_PHPMYADMIN" != "Y" ]; then
        return
    fi
    
    echo -e "${BLUE}=== 安装phpMyAdmin ===${NC}"
    
    # 获取最新的phpMyAdmin版本
    PHPMYADMIN_VERSION=$(curl -s https://www.phpmyadmin.net/downloads/ | grep -oP '(?<=phpMyAdmin-)[0-9.]+(?=-all-languages\.zip)' | head -1)
    
    if [ -z "$PHPMYADMIN_VERSION" ]; then
        PHPMYADMIN_VERSION="5.2.1"  # 默认版本
        echo -e "${YELLOW}无法获取最新phpMyAdmin版本，使用默认版本: $PHPMYADMIN_VERSION${NC}"
    fi
    
    # 下载phpMyAdmin
    wget -q -O /tmp/phpmyadmin.zip "https://files.phpmyadmin.net/phpMyAdmin/${PHPMYADMIN_VERSION}/phpMyAdmin-${PHPMYADMIN_VERSION}-all-languages.zip" >> $LOG_FILE 2>&1
    
    if [ ! -f "/tmp/phpmyadmin.zip" ]; then
        echo -e "${RED}phpMyAdmin下载失败，请检查连接或手动安装${NC}"
        return
    fi
    
    # 解压phpMyAdmin
    mkdir -p "$WEB_ROOT/phpmyadmin"
    unzip -q /tmp/phpmyadmin.zip -d /tmp/ >> $LOG_FILE 2>&1
    cp -a /tmp/phpMyAdmin-$PHPMYADMIN_VERSION-all-languages/. "$WEB_ROOT/phpmyadmin/"
    rm -rf /tmp/phpMyAdmin-$PHPMYADMIN_VERSION-all-languages
    rm -f /tmp/phpmyadmin.zip
    
    # 创建配置文件
    cp "$WEB_ROOT/phpmyadmin/config.sample.inc.php" "$WEB_ROOT/phpmyadmin/config.inc.php"
    
    # 生成随机blowfish密钥
    BLOWFISH_SECRET=$(tr -dc 'A-Za-z0-9!@#$%^&*()-_=+[]{}|;:,.<>?' < /dev/urandom | head -c 32)
    sed -i "s|\$cfg\['blowfish_secret'\] = ''|\$cfg\['blowfish_secret'\] = '$BLOWFISH_SECRET'|" "$WEB_ROOT/phpmyadmin/config.inc.php"
    
    # 设置适当的权限
    if [[ "$OS" == *"Ubuntu"* ]] || [[ "$OS" == *"Debian"* ]]; then
        chown -R www-data:www-data "$WEB_ROOT/phpmyadmin"
    elif [[ "$OS" == *"CentOS"* ]] || [[ "$OS" == *"Red Hat"* ]]; then
        chown -R apache:apache "$WEB_ROOT/phpmyadmin"
    fi
    
    echo -e "${GREEN}phpMyAdmin $PHPMYADMIN_VERSION 安装成功${NC}"
    echo -e "${GREEN}可通过 http://your-server-ip/phpmyadmin/ 访问${NC}"
}

# 配置安全设置函数
configure_security() {
    if [ "$CONFIGURE_SECURITY" != "y" ] && [ "$CONFIGURE_SECURITY" != "Y" ]; then
        return
    fi
    
    echo -e "${BLUE}=== 配置基本安全设置 ===${NC}"
    
    # 1. 配置Apache安全选项
    if [[ "$OS" == *"Ubuntu"* ]] || [[ "$OS" == *"Debian"* ]]; then
        # 隐藏Apache版本信息
        if ! grep -q "ServerTokens Prod" /etc/apache2/conf-enabled/security.conf; then
            sed -i 's/^ServerTokens OS/ServerTokens Prod/' /etc/apache2/conf-enabled/security.conf
        fi
        if ! grep -q "ServerSignature Off" /etc/apache2/conf-enabled/security.conf; then
            sed -i 's/^ServerSignature On/ServerSignature Off/' /etc/apache2/conf-enabled/security.conf
        fi
        
        # 禁用目录列表
        a2dismod -f autoindex >> $LOG_FILE 2>&1
        
        # 启用安全相关模块
        a2enmod headers >> $LOG_FILE 2>&1
        
        # 添加安全头
        if ! grep -q "X-Content-Type-Options" /etc/apache2/conf-enabled/security.conf; then
            cat >> /etc/apache2/conf-enabled/security.conf << EOF

# 添加安全头
<IfModule mod_headers.c>
    Header set X-Content-Type-Options: "nosniff"
    Header set X-Frame-Options: "SAMEORIGIN"
    Header set X-XSS-Protection: "1; mode=block"
    Header set Strict-Transport-Security: "max-age=31536000; includeSubDomains"
</IfModule>
EOF
        fi
        
        # 重启Apache以应用更改
        systemctl restart apache2 >> $LOG_FILE 2>&1
        
    elif [[ "$OS" == *"CentOS"* ]] || [[ "$OS" == *"Red Hat"* ]]; then
        # 隐藏Apache版本信息
        if ! grep -q "ServerTokens Prod" /etc/httpd/conf/httpd.conf; then
            echo "ServerTokens Prod" >> /etc/httpd/conf/httpd.conf
        fi
        if ! grep -q "ServerSignature Off" /etc/httpd/conf/httpd.conf; then
            echo "ServerSignature Off" >> /etc/httpd/conf/httpd.conf
        fi
        
        # 禁用目录列表
        sed -i 's/Options Indexes FollowSymLinks/Options FollowSymLinks/' /etc/httpd/conf/httpd.conf
        
        # 添加安全头
        cat > /etc/httpd/conf.d/security.conf << EOF
# 安全设置
<IfModule mod_headers.c>
    Header set X-Content-Type-Options: "nosniff"
    Header set X-Frame-Options: "SAMEORIGIN"
    Header set X-XSS-Protection: "1; mode=block"
    Header set Strict-Transport-Security: "max-age=31536000; includeSubDomains"
</IfModule>
EOF
        
        # 重启Apache以应用更改
        systemctl restart httpd >> $LOG_FILE 2>&1
    fi
    
    # 2. 配置PHP安全选项
    PHP_INI_FILE=""
    if [[ "$OS" == *"Ubuntu"* ]] || [[ "$OS" == *"Debian"* ]]; then
        PHP_INI_FILE="/etc/php/$PHP_VERSION/apache2/php.ini"
    elif [[ "$OS" == *"CentOS"* ]] || [[ "$OS" == *"Red Hat"* ]]; then
        PHP_INI_FILE="/etc/php.ini"
    fi
    
    if [ -f "$PHP_INI_FILE" ]; then
        # 禁用危险函数
        sed -i 's/^disable_functions =.*/disable_functions = exec,passthru,shell_exec,system,proc_open,popen,curl_exec,curl_multi_exec,parse_ini_file,show_source/' "$PHP_INI_FILE"
        
        # 隐藏PHP版本
        sed -i 's/^expose_php =.*/expose_php = Off/' "$PHP_INI_FILE"
        
        # 禁用远程文件包含
        sed -i 's/^allow_url_fopen =.*/allow_url_fopen = Off/' "$PHP_INI_FILE"
        sed -i 's/^allow_url_include =.*/allow_url_include = Off/' "$PHP_INI_FILE"
        
        # 设置上传限制
        sed -i 's/^upload_max_filesize =.*/upload_max_filesize = 10M/' "$PHP_INI_FILE"
        sed -i 's/^post_max_size =.*/post_max_size = 10M/' "$PHP_INI_FILE"
        sed -i 's/^memory_limit =.*/memory_limit = 256M/' "$PHP_INI_FILE"
        sed -i 's/^max_execution_time =.*/max_execution_time = 60/' "$PHP_INI_FILE"
        
        # 错误处理（生产环境设置）
        sed -i 's/^display_errors =.*/display_errors = Off/' "$PHP_INI_FILE"
        sed -i 's/^display_startup_errors =.*/display_startup_errors = Off/' "$PHP_INI_FILE"
        sed -i 's/^error_reporting =.*/error_reporting = E_ALL \& ~E_DEPRECATED \& ~E_STRICT/' "$PHP_INI_FILE"
        sed -i 's/^log_errors =.*/log_errors = On/' "$PHP_INI_FILE"
        
        # 重启Web服务器以应用PHP更改
        if [[ "$OS" == *"Ubuntu"* ]] || [[ "$OS" == *"Debian"* ]]; then
            systemctl restart apache2 >> $LOG_FILE 2>&1
        elif [[ "$OS" == *"CentOS"* ]] || [[ "$OS" == *"Red Hat"* ]]; then
            systemctl restart httpd >> $LOG_FILE 2>&1
        fi
    fi
    
    # 3. 配置MySQL/MariaDB安全选项
    MYSQL_CNF=""
    if [[ "$OS" == *"Ubuntu"* ]] || [[ "$OS" == *"Debian"* ]]; then
        MYSQL_CNF="/etc/mysql/mysql.conf.d/mysqld.cnf"
        if [ ! -f "$MYSQL_CNF" ]; then
            MYSQL_CNF="/etc/mysql/mariadb.conf.d/50-server.cnf"
        fi
    elif [[ "$OS" == *"CentOS"* ]] || [[ "$OS" == *"Red Hat"* ]]; then
        MYSQL_CNF="/etc/my.cnf"
    fi
    
    if [ -f "$MYSQL_CNF" ]; then
        # 使MySQL仅监听本地
        if ! grep -q "bind-address" "$MYSQL_CNF"; then
            sed -i '/\[mysqld\]/a bind-address = 127.0.0.1' "$MYSQL_CNF"
        else
            sed -i 's/^bind-address.*/bind-address = 127.0.0.1/' "$MYSQL_CNF"
        fi
        
        # 重启MySQL/MariaDB以应用更改
        if [[ "$OS" == *"Ubuntu"* ]] || [[ "$OS" == *"Debian"* ]]; then
            systemctl restart mysql >> $LOG_FILE 2>&1
        elif [[ "$OS" == *"CentOS"* ]] || [[ "$OS" == *"Red Hat"* ]]; then
            systemctl restart mariadb >> $LOG_FILE 2>&1
        fi
    fi
    
    # 4. 创建一个基本的.htaccess文件
    cat > "$WEB_ROOT/.htaccess" << EOF
# 基本安全设置
Options -Indexes
ServerSignature Off

# 防止访问敏感文件
<FilesMatch "^\.ht">
    Require all denied
</FilesMatch>

<FilesMatch "^(\.user.ini|composer\.json|composer\.lock|web\.config|\.env|\.gitignore)$">
    Require all denied
</FilesMatch>

# 防止PHP文件在上传目录执行
<IfModule mod_rewrite.c>
    RewriteEngine On
    RewriteRule ^uploads/.*\.(php|phtml|php3|php4|php5|php7)$ - [F]
</IfModule>
EOF
    
    # 设置适当的权限
    if [[ "$OS" == *"Ubuntu"* ]] || [[ "$OS" == *"Debian"* ]]; then
        chown www-data:www-data "$WEB_ROOT/.htaccess"
    elif [[ "$OS" == *"CentOS"* ]] || [[ "$OS" == *"Red Hat"* ]]; then
        chown apache:apache "$WEB_ROOT/.htaccess"
    fi
    
    echo -e "${GREEN}基本安全设置已配置完成${NC}"
}

# 创建示例页面
create_example_page() {
    echo -e "${BLUE}=== 创建示例页面 ===${NC}"
    
    # 创建index.php
    cat > "$WEB_ROOT/index.php" << EOF
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LAMP环境测试页面</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: #f9f9f9;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }
        h1 {
            color: #4CAF50;
            border-bottom: 2px solid #4CAF50;
            padding-bottom: 10px;
        }
        .info-box {
            background-color: #e9f5e9;
            border-left: 5px solid #4CAF50;
            padding: 15px;
            margin: 20px 0;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        table, th, td {
            border: 1px solid #ddd;
        }
        th, td {
            padding: 12px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
        .links {
            margin-top: 30px;
        }
        .links a {
            display: inline-block;
            margin-right: 15px;
            color: #0066cc;
            text-decoration: none;
        }
        .links a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>LAMP环境测试页面</h1>
        
        <div class="info-box">
            <p><strong>服务器环境安装成功！</strong> 这是一个由LAMP自动部署脚本创建的测试页面。</p>
        </div>
        
        <h2>服务器信息</h2>
        <table>
            <tr>
                <th>组件</th>
                <th>版本</th>
            </tr>
            <tr>
                <td>操作系统</td>
                <td><?= php_uname('s') . ' ' . php_uname('r'); ?></td>
            </tr>
            <tr>
                <td>Web服务器</td>
                <td><?= \$_SERVER['SERVER_SOFTWARE']; ?></td>
            </tr>
            <tr>
                <td>PHP版本</td>
                <td><?= PHP_VERSION; ?></td>
            </tr>
            <tr>
                <td>MySQL版本</td>
                <td>
                <?php
                try {
                    \$pdo = new PDO('mysql:host=localhost;', 'root', '$MYSQL_ROOT_PASS');
                    echo \$pdo->getAttribute(PDO::ATTR_SERVER_VERSION);
                } catch (PDOException \$e) {
                    echo '无法连接到数据库: ' . \$e->getMessage();
                }
                ?>
                </td>
            </tr>
        </table>
        
        <h2>PHP扩展</h2>
        <table>
            <tr>
                <th>扩展名</th>
                <th>状态</th>
            </tr>
            <?php
            \$extensions = ['mysqli', 'pdo_mysql', 'gd', 'curl', 'mbstring', 'xml', 'zip'];
            foreach (\$extensions as \$ext) {
                echo '<tr>';
                echo '<td>' . \$ext . '</td>';
                echo '<td>' . (extension_loaded(\$ext) ? '✓ 已加载' : '✗ 未加载') . '</td>';
                echo '</tr>';
            }
            ?>
        </table>
        
        <div class="links">
            <h2>有用的链接</h2>
            <a href="/phpinfo.php">PHP信息</a>
            <?php if (file_exists($_SERVER['DOCUMENT_ROOT'] . '/phpmyadmin')): ?>
            <a href="/phpmyadmin/">phpMyAdmin</a>
            <?php endif; ?>
        </div>
        
        <div class="info-box">
            <p>
                <strong>安全提示：</strong> 出于安全考虑，建议在完成测试后从Web根目录删除此页面和phpinfo.php文件。
            </p>
        </div>
    </div>
</body>
</html>
EOF
    
    # 设置适当的权限
    if [[ "$OS" == *"Ubuntu"* ]] || [[ "$OS" == *"Debian"* ]]; then
        chown www-data:www-data "$WEB_ROOT/index.php"
    elif [[ "$OS" == *"CentOS"* ]] || [[ "$OS" == *"Red Hat"* ]]; then
        chown apache:apache "$WEB_ROOT/index.php"
    fi
    
    echo -e "${GREEN}示例页面已创建${NC}"
}

# 主执行流程
update_system
install_apache
install_mysql
install_php
install_phpmyadmin
configure_security
create_example_page

# 显示总结信息
echo -e "\n${GREEN}=== LAMP环境安装完成! ===${NC}"

# 获取服务器IP
SERVER_IP=$(hostname -I | awk '{print $1}')
if [ -z "$SERVER_IP" ]; then
    SERVER_IP="your-server-ip"
fi

echo -e "${BLUE}服务器IP: ${GREEN}$SERVER_IP${NC}"
echo -e "${BLUE}Web根目录: ${GREEN}$WEB_ROOT${NC}"
echo -e "${BLUE}MySQL/MariaDB根密码: ${GREEN}$MYSQL_ROOT_PASS${NC}"
echo -e "\n${BLUE}可通过以下链接访问:${NC}"
echo -e "  ${GREEN}http://$SERVER_IP/${NC} - 首页"
echo -e "  ${GREEN}http://$SERVER_IP/phpinfo.php${NC} - PHP信息"

if [ "$INSTALL_PHPMYADMIN" = "y" ] || [ "$INSTALL_PHPMYADMIN" = "Y" ]; then
    echo -e "  ${GREEN}http://$SERVER_IP/phpmyadmin/${NC} - phpMyAdmin管理界面"
fi

echo -e "\n${YELLOW}安全提示:${NC}"
echo -e "  - 请妥善保存MySQL根密码"
echo -e "  - 在完成测试后删除phpinfo.php文件"
echo -e "  - 根据需要定期更新系统和软件包\n"

echo -e "${BLUE}安装日志: ${GREEN}$LOG_FILE${NC}\n"
```

这个脚本提供了一个完整的LAMP环境自动部署解决方案，适用于Debian/Ubuntu和CentOS/RHEL系统。它不仅安装了Apache、MySQL/MariaDB和PHP，还提供了phpMyAdmin选项和基本的安全配置，非常适合快速部署开发或生产环境。


